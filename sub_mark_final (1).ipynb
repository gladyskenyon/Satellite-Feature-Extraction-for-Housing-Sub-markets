{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccb1e59d-eb6b-4439-ba7d-1455df4da73d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Extracting features from Satelleite imagery and clustering areas into groups based on these features, to identify housing-submnarkets "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf5e89c-a0b5-4cbf-a245-cfd9180d6895",
   "metadata": {},
   "source": [
    "The following notebook implements the MOSAIKs model to extract features from satelleiete imagery in Madrid. The features are extracted for different patch sizes and then these features are clustered to create housing sub-markets. We finally calculate some internal validation scores to assess the cluster quality across scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8fc8cc2f-7ae8-4975-9d72-ce17a1665eeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in packages\n",
    "import warnings\n",
    "import time\n",
    "import os\n",
    "\n",
    "RASTERIO_BEST_PRACTICES = dict(  # See https://github.com/pangeo-data/cog-best-practices\n",
    "    CURL_CA_BUNDLE=\"/etc/ssl/certs/ca-certificates.crt\",\n",
    "    GDAL_DISABLE_READDIR_ON_OPEN=\"EMPTY_DIR\",\n",
    "    AWS_NO_SIGN_REQUEST=\"YES\",\n",
    "    GDAL_MAX_RAW_BLOCK_CACHE_SIZE=\"200000000\",\n",
    "    GDAL_SWATH_SIZE=\"200000000\",\n",
    "    VSI_CURL_CACHE_SIZE=\"200000000\",\n",
    ")\n",
    "os.environ.update(RASTERIO_BEST_PRACTICES)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import rasterio\n",
    "import rasterio.warp\n",
    "import rasterio.mask\n",
    "import shapely.geometry\n",
    "import geopandas\n",
    "import dask_geopandas\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.linalg import LinAlgWarning\n",
    "from dask.distributed import Client\n",
    "import pystac_client\n",
    "import planetary_computer as pc\n",
    "import contextily as cx\n",
    "import geopandas as gpd\n",
    "from sklearn.cluster import KMeans\n",
    "from shapely import wkt\n",
    "from sklearn.preprocessing import robust_scale\n",
    "warnings.filterwarnings(action=\"ignore\", category=LinAlgWarning, module=\"sklearn\")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from shapely.geometry import shape\n",
    "from shapely.geometry import Point, box\n",
    "\n",
    "import gap_statistic\n",
    "from gap_statistic import OptimalK\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8a79e37d-ba2d-416e-bc81-510b9ccfdd69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /srv/conda/envs/notebook/lib/python3.11/site-packages (2.2.1)\n",
      "Requirement already satisfied: filelock in /srv/conda/envs/notebook/lib/python3.11/site-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in /srv/conda/envs/notebook/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /srv/conda/envs/notebook/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /srv/conda/envs/notebook/lib/python3.11/site-packages (from torch) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1d583e87-9510-40f8-8297-2f7ff0111994",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gap-stat in /srv/conda/envs/notebook/lib/python3.11/site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in /srv/conda/envs/notebook/lib/python3.11/site-packages (from gap-stat) (1.24.3)\n",
      "Requirement already satisfied: pandas in /srv/conda/envs/notebook/lib/python3.11/site-packages (from gap-stat) (2.0.2)\n",
      "Requirement already satisfied: scipy in /srv/conda/envs/notebook/lib/python3.11/site-packages (from gap-stat) (1.10.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from pandas->gap-stat) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from pandas->gap-stat) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from pandas->gap-stat) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->gap-stat) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gap-stat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f45b0a-81b1-44a9-a2b3-f935a4090818",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "64e4f0e1-47cd-4fef-a56a-46d74bca74c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in shapefile of Madrid with district boundaries\n",
    "db = gpd.read_file('Distritos.shp')\n",
    "# Set local crs in m \n",
    "db = db.to_crs(25830)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2ddeaff8-caf2-42c6-a9f4-f503911c2698",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize grid_list\n",
    "grid_list = []\n",
    "\n",
    "# Set the initial CRS and step size\n",
    "crs = '25830'\n",
    "initial_step = 300\n",
    "\n",
    "# Total bounds of the original GeoDataFrame (assuming it's called db)\n",
    "a, b, c, d = db.total_bounds\n",
    "\n",
    "# Create a grid for geometry with step size 300\n",
    "gdf_grid = gpd.GeoDataFrame(\n",
    "    geometry=[\n",
    "        shapely.geometry.box(minx, miny, maxx, maxy)\n",
    "        for minx, maxx in zip(np.arange(a, c, initial_step), np.arange(a, c, initial_step)[1:])\n",
    "        for miny, maxy in zip(np.arange(b, d, initial_step), np.arange(b, d, initial_step)[1:])\n",
    "    ],\n",
    "    crs=crs,\n",
    ").to_crs(db.crs)\n",
    "\n",
    "# Append the grid to grid_list\n",
    "grid_list.append(gdf_grid)\n",
    "\n",
    "\n",
    "# Create grids to patch image\n",
    "# Change the step size to change sizes\n",
    "# Set the initial CRS and step size\n",
    "crs = '25830'\n",
    "initial_step = 500\n",
    "final_step = 4000\n",
    "step_increase = 400\n",
    "\n",
    "\n",
    "# Loop through step sizes\n",
    "for STEP in range(initial_step, final_step + 1, step_increase):\n",
    "    # Total bounds of the original GeoDataFrame (assuming it's called db)\n",
    "    a, b, c, d = db.total_bounds\n",
    "\n",
    "    # Create a grid for geometry\n",
    "    gdf_grid = gpd.GeoDataFrame(\n",
    "        geometry=[\n",
    "            shapely.geometry.box(minx, miny, maxx, maxy)\n",
    "            for minx, maxx in zip(np.arange(a, c, STEP), np.arange(a, c, STEP)[1:])\n",
    "            for miny, maxy in zip(np.arange(b, d, STEP), np.arange(b, d, STEP)[1:])\n",
    "        ],\n",
    "        crs=crs,\n",
    "    ).to_crs(db.crs)\n",
    "\n",
    "    # Append the current GeoDataFrame to the list\n",
    "    grid_list.append(gdf_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f8ec8267-cd58-4a2c-80a8-8b2a9f011a05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POLYGON ((425053.609 4462565.990, 425053.609 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POLYGON ((425053.609 4462865.990, 425053.609 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POLYGON ((425053.609 4463165.990, 425053.609 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POLYGON ((425053.609 4463465.990, 425053.609 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POLYGON ((425053.609 4463765.990, 425053.609 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12683</th>\n",
       "      <td>POLYGON ((455953.609 4497665.990, 455953.609 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12684</th>\n",
       "      <td>POLYGON ((455953.609 4497965.990, 455953.609 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12685</th>\n",
       "      <td>POLYGON ((455953.609 4498265.990, 455953.609 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12686</th>\n",
       "      <td>POLYGON ((455953.609 4498565.990, 455953.609 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12687</th>\n",
       "      <td>POLYGON ((455953.609 4498865.990, 455953.609 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12688 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                geometry\n",
       "0      POLYGON ((425053.609 4462565.990, 425053.609 4...\n",
       "1      POLYGON ((425053.609 4462865.990, 425053.609 4...\n",
       "2      POLYGON ((425053.609 4463165.990, 425053.609 4...\n",
       "3      POLYGON ((425053.609 4463465.990, 425053.609 4...\n",
       "4      POLYGON ((425053.609 4463765.990, 425053.609 4...\n",
       "...                                                  ...\n",
       "12683  POLYGON ((455953.609 4497665.990, 455953.609 4...\n",
       "12684  POLYGON ((455953.609 4497965.990, 455953.609 4...\n",
       "12685  POLYGON ((455953.609 4498265.990, 455953.609 4...\n",
       "12686  POLYGON ((455953.609 4498565.990, 455953.609 4...\n",
       "12687  POLYGON ((455953.609 4498865.990, 455953.609 4...\n",
       "\n",
       "[12688 rows x 1 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed190384-c06a-4561-b1e7-4830ca260396",
   "metadata": {},
   "source": [
    "## Satelleite data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "401c15ce-188a-4ba3-8efc-e798626b39c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a points dataframe to retrieve satelleite imagery\n",
    "grid_list[9].crs = \"EPSG:25830\"\n",
    "\n",
    "# Create a new GeoDataFrame with centroids pf grid cells\n",
    "points = gpd.GeoDataFrame(geometry=grid_list[9].geometry.centroid, crs=grid_list[9].crs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8cbfaa71-4863-431b-94e0-eca4fdd571e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use dask to partition the data for one dataframe\n",
    "\n",
    "NPARTITIONS = 250\n",
    "\n",
    "ddf = dask_geopandas.from_geopandas(points, npartitions=1)\n",
    "#hd = ddf.hilbert_distance().compute()\n",
    "#points[\"hd\"] = hd\n",
    "#points = points.sort_values(\"hd\")\n",
    "points = points.to_crs(4326)\n",
    "\n",
    "dgdf = dask_geopandas.from_geopandas(points, npartitions=NPARTITIONS, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cdb2f35e-3cea-46b5-bcbe-c1a38aed6f4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use STAC to fetch satelleite imagery\n",
    "time_of_interest = \"2019-02-13\"\n",
    "\n",
    "def query(points):\n",
    "    \"\"\"\n",
    "    Find a STAC item for points in the `points` DataFrame\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    points : geopandas.GeoDataFrame\n",
    "        A GeoDataFrame\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    geopandas.GeoDataFrame\n",
    "        A new geopandas.GeoDataFrame with a `stac_item` column containing the STAC\n",
    "        item that covers each point.\n",
    "    \"\"\"\n",
    "    intersects = shapely.geometry.mapping(points.unary_union.convex_hull)\n",
    "    catalog = pystac_client.Client.open(\n",
    "        \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n",
    "    )\n",
    "\n",
    "    # The time frame in which we search for non-cloudy imagery\n",
    "    search = catalog.search(\n",
    "        collections=[\"sentinel-2-l2a\"],\n",
    "        intersects=intersects,\n",
    "        datetime=time_of_interest,\n",
    "        query={\"eo:cloud_cover\": {\"lt\": 10}},\n",
    "        limit=500,\n",
    "    )\n",
    "    ic = search.get_all_items_as_dict()\n",
    "\n",
    "    features = ic[\"features\"]\n",
    "    features_d = {item[\"id\"]: item for item in features}\n",
    "\n",
    "    data = {\n",
    "        \"eo:cloud_cover\": [],\n",
    "        \"geometry\": [],\n",
    "    }\n",
    "\n",
    "    index = []\n",
    "\n",
    "    for item in features:\n",
    "        data[\"eo:cloud_cover\"].append(item[\"properties\"][\"eo:cloud_cover\"])\n",
    "        data[\"geometry\"].append(shapely.geometry.shape(item[\"geometry\"]))\n",
    "        index.append(item[\"id\"])\n",
    "\n",
    "    items = geopandas.GeoDataFrame(data, index=index, geometry=\"geometry\").sort_values(\n",
    "        \"eo:cloud_cover\"\n",
    "    )\n",
    "    point_list = points.geometry.tolist()\n",
    "\n",
    "    point_items = []\n",
    "    for point in point_list:\n",
    "        covered_by = items[items.covers(point)]\n",
    "        if len(covered_by):\n",
    "            point_items.append(features_d[covered_by.index[0]])\n",
    "        else:\n",
    "            # There weren't any scenes matching our conditions for this point (too cloudy)\n",
    "            point_items.append(None)\n",
    "\n",
    "    return points.assign(stac_item=point_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1d931ac3-dc83-4929-a200-8945f528844c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 2 µs, total: 5 µs\n",
      "Wall time: 17.4 µs\n",
      "/user/g.e.kenyon@liverpool.ac.uk/proxy/8787/status\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/pystac_client/item_search.py:856: FutureWarning: get_all_items_as_dict() is deprecated, use item_collection_as_dict() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Assign stac item to df2\n",
    "%time\n",
    "\n",
    "with Client(n_workers=16) as client:\n",
    "    print(client.dashboard_link)\n",
    "    meta = dgdf._meta.assign(stac_item=[])\n",
    "    df2 = dgdf.map_partitions(query, meta=meta).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7cdf41c1-2b83-4693-8116-e97c015a44dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming 'grid_list' is your list of GeoDataFrames\n",
    "for idx, gdf_grid in enumerate(grid_list):\n",
    "    # Access the 'stac_item' dictionary for the specified row in df2\n",
    "    stac_item_dict = df2.loc[idx, 'stac_item']\n",
    "\n",
    "    # Repeat the 'stac_item' value for the entire length of the GeoDataFrame\n",
    "    repeated_stac_item = pd.Series([stac_item_dict] * len(gdf_grid), index=gdf_grid.index)\n",
    "\n",
    "    # Assign the repeated 'stac_item' to the 'stac_item' column in the current GeoDataFrame\n",
    "    gdf_grid['stac_item'] = repeated_stac_item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4221c019-4693-4af0-bb27-47096a24ed9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a list to store matching URLs for each GeoDataFrame\n",
    "matching_urls_list = []\n",
    "\n",
    "for idx, gdf_grid in enumerate(grid_list):\n",
    "    # Access the 'stac_item' dictionary for the specified row in df2\n",
    "    stac_item_dict = df2.loc[idx, 'stac_item']\n",
    "\n",
    "    # Extract the 'visual' asset href from the 'stac_item' dictionary\n",
    "    visual_href = stac_item_dict[\"assets\"][\"visual\"][\"href\"]\n",
    "\n",
    "    # Sign the URL\n",
    "    signed_url = pc.sign(visual_href)\n",
    "\n",
    "    # Create a list with the signed URL repeated for each observation in the GeoDataFrame\n",
    "    matching_urls = [signed_url] * len(gdf_grid)\n",
    "\n",
    "    # Append the list of matching URLs to the overall list\n",
    "    matching_urls_list.append(matching_urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "008dccaf-e8a5-4a99-9d27-71f7590ca3cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of GeoDataFrame at index 0: 12688\n",
      "Length of matching URLs at index 0: 12688\n",
      "Length of GeoDataFrame at index 1: 4526\n",
      "Length of matching URLs at index 1: 4526\n",
      "Length of GeoDataFrame at index 2: 1360\n",
      "Length of matching URLs at index 2: 1360\n",
      "Length of GeoDataFrame at index 3: 672\n",
      "Length of matching URLs at index 3: 672\n",
      "Length of GeoDataFrame at index 4: 378\n",
      "Length of matching URLs at index 4: 378\n",
      "Length of GeoDataFrame at index 5: 238\n",
      "Length of matching URLs at index 5: 238\n",
      "Length of GeoDataFrame at index 6: 168\n",
      "Length of matching URLs at index 6: 168\n",
      "Length of GeoDataFrame at index 7: 120\n",
      "Length of matching URLs at index 7: 120\n",
      "Length of GeoDataFrame at index 8: 99\n",
      "Length of matching URLs at index 8: 99\n",
      "Length of GeoDataFrame at index 9: 72\n",
      "Length of matching URLs at index 9: 72\n"
     ]
    }
   ],
   "source": [
    "# The length of urls and grid squares should match\n",
    "for idx, (urls, grid_list) in enumerate(zip(matching_urls_list, grid_list)):\n",
    "    print(f\"Length of GeoDataFrame at index {idx}: {len(grid_list)}\")\n",
    "    print(f\"Length of matching URLs at index {idx}: {len(urls)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dbbc64-e5b9-43b9-b341-7fc7969b8d61",
   "metadata": {},
   "source": [
    "### Patch Satelleite data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0389cd45-39b2-4126-b8e9-6c9ef4dfbc2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define custom pytorch dataset to load raster data, cropping it based on grid cell geometries, and providing the preprocessed image data for training or inference in PyTorch.\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, gdf_grid, fns):\n",
    "        self.gdf_grid = gdf_grid\n",
    "        self.fns = fns\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.gdf_grid)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fn = self.fns[idx]\n",
    "\n",
    "        if fn is None:\n",
    "            return None\n",
    "        else:\n",
    "            # Get the geometry of the current grid cell\n",
    "            grid_geom = self.gdf_grid.iloc[idx].geometry\n",
    "\n",
    "            with rasterio.Env():\n",
    "                with rasterio.open(fn, \"r\") as f:\n",
    "                    # Crop the raster to the grid cell\n",
    "                    out_image, out_transform = rasterio.mask.mask(\n",
    "                        f, [shapely.geometry.mapping(grid_geom)], crop=True\n",
    "                    )\n",
    "            # Get the dimensions of the valid part of the image\n",
    "            height, width = out_image.shape[1:]\n",
    "\n",
    "            # Remove the last row and column\n",
    "            out_image = out_image[:, :height - 1, :width - 1]\n",
    "\n",
    "    \n",
    "            out_image = out_image / 255.0\n",
    "            out_image = torch.from_numpy(out_image).float()\n",
    "\n",
    "            # Return the image\n",
    "            return out_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e548a59e-0d1d-431e-8ef1-204736ea607b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize grid_list\n",
    "grid_list = []\n",
    "\n",
    "# Set the initial CRS and step size\n",
    "crs = '25830'\n",
    "initial_step = 300\n",
    "\n",
    "# Total bounds of the original GeoDataFrame (assuming it's called db)\n",
    "a, b, c, d = db.total_bounds\n",
    "\n",
    "# Create a grid for geometry with step size 300\n",
    "gdf_grid = gpd.GeoDataFrame(\n",
    "    geometry=[\n",
    "        shapely.geometry.box(minx, miny, maxx, maxy)\n",
    "        for minx, maxx in zip(np.arange(a, c, initial_step), np.arange(a, c, initial_step)[1:])\n",
    "        for miny, maxy in zip(np.arange(b, d, initial_step), np.arange(b, d, initial_step)[1:])\n",
    "    ],\n",
    "    crs=crs,\n",
    ").to_crs(db.crs)\n",
    "\n",
    "# Append the grid to grid_list\n",
    "grid_list.append(gdf_grid)\n",
    "\n",
    "\n",
    "# Create grids to patch image\n",
    "# Change the step size to change sizes\n",
    "# Set the initial CRS and step size\n",
    "crs = '25830'\n",
    "initial_step = 500\n",
    "final_step = 4000\n",
    "step_increase = 400\n",
    "\n",
    "\n",
    "# Loop through step sizes\n",
    "for STEP in range(initial_step, final_step + 1, step_increase):\n",
    "    # Total bounds of the original GeoDataFrame (assuming it's called db)\n",
    "    a, b, c, d = db.total_bounds\n",
    "\n",
    "    # Create a grid for geometry\n",
    "    gdf_grid = gpd.GeoDataFrame(\n",
    "        geometry=[\n",
    "            shapely.geometry.box(minx, miny, maxx, maxy)\n",
    "            for minx, maxx in zip(np.arange(a, c, STEP), np.arange(a, c, STEP)[1:])\n",
    "            for miny, maxy in zip(np.arange(b, d, STEP), np.arange(b, d, STEP)[1:])\n",
    "        ],\n",
    "        crs=crs,\n",
    "    ).to_crs(db.crs)\n",
    "\n",
    "    # Append the current GeoDataFrame to the list\n",
    "    grid_list.append(gdf_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f8eae62f-839d-4efe-8b82-abcf2e4582cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List to store dataloaders\n",
    "dataloaders = []\n",
    "\n",
    "# Iterate over each item in processed_points_list\n",
    "for idx in range(len(grid_list)):\n",
    "    # Increase buffer size in increments of 50\n",
    "    # Create a CustomDataset for each item with the respective buffer size\n",
    "    dataset = CustomDataset(grid_list[idx], matching_urls_list[idx])\n",
    "\n",
    "    # Create a DataLoader for each dataset\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=8,\n",
    "        shuffle=False,\n",
    "        num_workers=os.cpu_count() * 2,\n",
    "        collate_fn=lambda x: x,\n",
    "        pin_memory=False,\n",
    "    )\n",
    "\n",
    "    # Append the dataloader to the list\n",
    "    dataloaders.append(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cd8d5b38-458f-4c47-9cbd-4a62da049b0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pick a dataloder to visualise - different scales\n",
    "first_dataloader = dataloaders[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4471a146-2c56-4af3-a1ce-95c80c6ccfb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Dimensions: torch.Size([3, 30, 30])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display an image patch \n",
    "# Assuming you want to display the first image patch\n",
    "desired_patch_index = 1\n",
    "\n",
    "# Assuming dataloader_0 contains the images\n",
    "images = next(iter(first_dataloader))\n",
    "\n",
    "# Select the desired patch\n",
    "image = images[desired_patch_index]\n",
    "\n",
    "if image is not None and image.shape[1] >= 0 and image.shape[2] >= 0:\n",
    "    # Print the dimensions of the image\n",
    "    print(\"Image Dimensions:\", image.shape)\n",
    "\n",
    "\n",
    "\n",
    "    # Visualize the image\n",
    "plt.imshow(image.permute(1, 2, 0))  # Assuming image is (C, H, W) and you want to convert to (H, W, C)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e93e64-4111-4041-bf98-9a3db64d41a7",
   "metadata": {},
   "source": [
    "### Run the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9d398618-7b57-4fe9-8a4e-f73f9767d66d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RCF(nn.Module):\n",
    "    \"\"\"A model for extracting Random Convolution Features (RCF) from input imagery.\"\"\"\n",
    "\n",
    "    def __init__(self, num_features=16, kernel_size=3, num_input_channels=3):\n",
    "        super(RCF, self).__init__()\n",
    "\n",
    "        # We create `num_features / 2` filters so require `num_features` to be divisible by 2\n",
    "        assert num_features % 2 == 0\n",
    "\n",
    "        self.num_features = num_features  # Store num_features as an instance variable\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            num_input_channels,\n",
    "            num_features // 2,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            dilation=1,\n",
    "            bias=True,\n",
    "        )\n",
    "\n",
    "        nn.init.normal_(self.conv1.weight, mean=0.0, std=1.0)\n",
    "        nn.init.constant_(self.conv1.bias, -1.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1a = F.relu(self.conv1(x), inplace=True)\n",
    "        x1b = F.relu(-self.conv1(x), inplace=True)\n",
    "\n",
    "        x1a = F.adaptive_avg_pool2d(x1a, (1, 1)).squeeze()\n",
    "        x1b = F.adaptive_avg_pool2d(x1b, (1, 1)).squeeze()\n",
    "\n",
    "        if len(x1a.shape) == 1:  # case where we passed a single input\n",
    "            return torch.cat((x1a, x1b), dim=0)\n",
    "        elif len(x1a.shape) == 2:  # case where we passed a batch of > 1 inputs\n",
    "            return torch.cat((x1a, x1b), dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c1d62f95-db0c-4461-9555-96a26fd21128",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the numbers of features for each model\n",
    "feature_numbers = [100, 500, 1000, 2000]\n",
    "\n",
    "# Create a list to store models\n",
    "models = []\n",
    "\n",
    "# Create models with different numbers of features\n",
    "for num_features in feature_numbers:\n",
    "#    device = torch.device(\"cuda\")\n",
    "    model = RCF(num_features=num_features).eval().to()\n",
    "    models.append(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7f6fd28c-e8b5-4426-94dd-548f14bd11ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#store centroid of patch co-ordinates\n",
    "processed_grid_list = []\n",
    "\n",
    "for gdf_grid in grid_list:\n",
    "    # Change to m crs if needed\n",
    "    gdf_grid = gdf_grid.to_crs(25830)\n",
    "\n",
    "    # Calculate the centroid of each polygon\n",
    "    centroids = gdf_grid.geometry.centroid\n",
    "\n",
    "    # Create a DataFrame with centroid coordinates\n",
    "    centroids_df = gpd.GeoDataFrame(geometry=centroids, crs=gdf_grid.crs)\n",
    "    centroids_df['west'] = centroids_df.geometry.x\n",
    "    centroids_df['east'] = centroids_df.geometry.y\n",
    "\n",
    "    # Extract necessary columns to form numpy array\n",
    "    centroids_array = centroids_df[[\"west\", \"east\"]].to_numpy()\n",
    "\n",
    "    # Append only the array to the processed_grid_list\n",
    "    processed_grid_list.append(centroids_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e9d91b-0ebb-4405-9678-36e191819817",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f8dde7-9ff8-44c8-a888-804e6ed083a8",
   "metadata": {},
   "source": [
    "We now run the model for different scales, we do this separately to not overload the memory. We start with the widest scale and work down to the smallest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1af95282-c077-4e87-97fe-71e9639e9459",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/72 -- 0.00% -- 3.49 seconds\n",
      "0/72 -- 0.00% -- 3.60 seconds\n",
      "0/72 -- 0.00% -- 3.82 seconds\n",
      "0/72 -- 0.00% -- 3.78 seconds\n",
      "Results for model with 100 features:\n",
      "[[0.         1.38054872 1.41883326 ... 2.96676683 2.00489902 0.21392314]\n",
      " [0.         1.15988469 1.31107295 ... 2.87394643 1.9663049  0.1459052 ]\n",
      " [0.         0.88463676 1.01130664 ... 2.60314846 1.828071   0.22929783]\n",
      " ...\n",
      " [0.         0.97611982 1.11941266 ... 2.71720338 1.88596189 0.18096825]\n",
      " [0.         0.91279328 1.1417712  ... 2.7465024  1.89951587 0.15911126]\n",
      " [0.         1.19146526 1.37046134 ... 2.92962742 1.99208891 0.15299864]]\n",
      "Results for model with 500 features:\n",
      "[[5.17911613e-01 4.20140076e+00 1.14497216e-02 ... 2.44811916e+00\n",
      "  6.83124131e-03 2.72062707e+00]\n",
      " [4.62471098e-01 4.05944300e+00 5.62252663e-03 ... 2.46237135e+00\n",
      "  1.63196784e-03 2.76617551e+00]\n",
      " [3.55218887e-01 3.34240508e+00 5.00541693e-03 ... 2.26258469e+00\n",
      "  2.87572686e-02 2.51805735e+00]\n",
      " ...\n",
      " [3.53486538e-01 3.63706732e+00 1.25826960e-02 ... 2.34114742e+00\n",
      "  4.46872134e-03 2.62450194e+00]\n",
      " [4.57166344e-01 3.73425889e+00 3.40311229e-03 ... 2.40448284e+00\n",
      "  8.34124349e-03 2.78033853e+00]\n",
      " [5.39868832e-01 4.19517612e+00 5.75072179e-03 ... 2.50735688e+00\n",
      "  6.22965675e-03 2.85987186e+00]]\n",
      "Results for model with 1000 features:\n",
      "[[1.14039390e-03 8.13858092e-01 3.48489791e-01 ... 5.02786003e-02\n",
      "  3.20202613e+00 2.10513806e+00]\n",
      " [7.33724504e-04 7.93154955e-01 3.02378416e-01 ... 1.54478075e-02\n",
      "  3.16138649e+00 2.08341622e+00]\n",
      " [1.04477769e-03 6.06841743e-01 2.38030121e-01 ... 5.65521196e-02\n",
      "  2.85323191e+00 1.92738605e+00]\n",
      " ...\n",
      " [2.95888894e-04 6.51419818e-01 2.13634565e-01 ... 1.37927886e-02\n",
      "  2.98308420e+00 1.99466956e+00]\n",
      " [3.23273969e-04 7.06583798e-01 2.46684656e-01 ... 1.96353421e-02\n",
      "  3.05680418e+00 2.04956412e+00]\n",
      " [7.93048763e-04 8.43317032e-01 3.34083021e-01 ... 1.93436220e-02\n",
      "  3.23221087e+00 2.12989259e+00]]\n",
      "Results for model with 2000 features:\n",
      "[[2.73608835e-03 5.64960837e-01 7.81402397e+00 ... 2.87117250e-03\n",
      "  1.75064123e+00 1.60711810e-01]\n",
      " [4.42565157e-04 4.50245351e-01 7.43523693e+00 ... 5.68165211e-04\n",
      "  1.72676623e+00 1.62542880e-01]\n",
      " [5.21417824e-04 3.40093881e-01 6.23543644e+00 ... 1.22602619e-02\n",
      "  1.61833847e+00 2.60777026e-01]\n",
      " ...\n",
      " [1.68750077e-04 3.39679152e-01 6.72545576e+00 ... 1.97090558e-03\n",
      "  1.66749454e+00 1.80430934e-01]\n",
      " [1.17894284e-04 3.30499291e-01 6.77029228e+00 ... 4.44784295e-03\n",
      "  1.70812130e+00 1.82875603e-01]\n",
      " [2.72973761e-04 4.79627162e-01 7.62670851e+00 ... 4.69184341e-03\n",
      "  1.76151347e+00 1.60134628e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to store results for each model\n",
    "output_dict9 = {}\n",
    "\n",
    "# Loop over each model\n",
    "for model in models:\n",
    "    x_all = np.zeros((processed_grid_list[9].shape[0], model.num_features), dtype=float)\n",
    "\n",
    "    tic = time.time()\n",
    "    i = 0\n",
    "\n",
    "    # Iterate over each image in the dataloader\n",
    "    for images in dataloaders[9]:\n",
    "        for image in images:\n",
    "            if image is not None and image.shape[1] >= 0 and image.shape[2] >= 0:\n",
    "                image = image.to()\n",
    "                with torch.no_grad():\n",
    "                    feats = model(image.unsqueeze(0)).cpu().numpy()\n",
    "\n",
    "                x_all[i] = feats\n",
    "\n",
    "                if i % 1000 == 0:\n",
    "                    print(\n",
    "                        f\"{i}/{processed_grid_list[9].shape[0]} -- {i / processed_grid_list[9].shape[0] * 100:0.2f}%\"\n",
    "                        + f\" -- {time.time()-tic:0.2f} seconds\"\n",
    "                    )\n",
    "                    tic = time.time()\n",
    "\n",
    "                i += 1\n",
    "\n",
    "                # Check if i exceeds the number of points, break the loop\n",
    "                if i >= processed_grid_list[9].shape[0]:\n",
    "                    break\n",
    "\n",
    "        # Check if i exceeds the number of points, break the loop\n",
    "        if i >= processed_grid_list[9].shape[0]:\n",
    "            break\n",
    "\n",
    "    # Store x_all in the dictionary for the current model\n",
    "    output_dict9[model.num_features] = x_all\n",
    "\n",
    "# Access the results for each model\n",
    "for num_features, x_all in output_dict9.items():\n",
    "    print(f\"Results for model with {num_features} features:\")\n",
    "    print(x_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "44c3476d-5319-465b-a028-a5e29d405303",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/99 -- 0.00% -- 3.14 seconds\n",
      "0/99 -- 0.00% -- 3.61 seconds\n",
      "0/99 -- 0.00% -- 3.86 seconds\n",
      "0/99 -- 0.00% -- 4.48 seconds\n",
      "Results for model with 100 features:\n",
      "[[0.         1.77074945 0.83179665 ... 5.09213543 0.08562321 4.71948481]\n",
      " [0.         1.71507907 0.82368302 ... 4.98868275 0.07152402 4.6389122 ]\n",
      " [0.         1.45019329 0.74532843 ... 4.82351446 0.09175567 4.46620131]\n",
      " ...\n",
      " [0.         1.31661367 0.67674124 ... 4.75376129 0.09502747 4.38814068]\n",
      " [0.         1.69944453 0.88816428 ... 5.23091936 0.07905821 4.82740974]\n",
      " [0.         1.2866776  0.66892815 ... 4.6839118  0.10340425 4.32262993]]\n",
      "Results for model with 500 features:\n",
      "[[4.47154045e-03 4.55908149e-01 9.98329744e-03 ... 3.85451913e+00\n",
      "  1.08361233e-03 2.81956387e+00]\n",
      " [9.41151578e-04 4.07022238e-01 3.84491822e-03 ... 3.79792237e+00\n",
      "  1.00265279e-04 2.79243302e+00]\n",
      " [3.53787298e-04 3.43103588e-01 1.17099541e-03 ... 3.56408286e+00\n",
      "  1.54375529e-03 2.72618866e+00]\n",
      " ...\n",
      " [1.66637212e-04 2.90836453e-01 6.54816686e-04 ... 3.45037770e+00\n",
      "  9.11414041e-04 2.68610001e+00]\n",
      " [3.74656083e-04 4.45467889e-01 9.90553410e-04 ... 3.83102369e+00\n",
      "  9.52195376e-04 2.89919066e+00]\n",
      " [3.19912710e-04 2.85634249e-01 9.44165513e-04 ... 3.40931106e+00\n",
      "  6.23624446e-03 2.65692401e+00]]\n",
      "Results for model with 1000 features:\n",
      "[[5.51700687e-05 0.00000000e+00 7.17840865e-02 ... 4.07088876e-01\n",
      "  6.91448431e-03 9.05805528e-01]\n",
      " [1.54630925e-05 0.00000000e+00 5.40578403e-02 ... 3.61008316e-01\n",
      "  8.55608610e-04 9.07042623e-01]\n",
      " [1.23423672e-06 0.00000000e+00 2.16055922e-02 ... 3.60556513e-01\n",
      "  4.20670444e-03 8.08714390e-01]\n",
      " ...\n",
      " [1.04466408e-05 0.00000000e+00 1.40329394e-02 ... 3.31869125e-01\n",
      "  3.88178066e-03 7.59042382e-01]\n",
      " [1.29518739e-05 0.00000000e+00 3.36674936e-02 ... 3.09668601e-01\n",
      "  2.51372298e-03 7.87643254e-01]\n",
      " [5.47698437e-06 0.00000000e+00 1.14124427e-02 ... 3.48321855e-01\n",
      "  9.08144191e-03 7.69208610e-01]]\n",
      "Results for model with 2000 features:\n",
      "[[1.19244032e-01 0.00000000e+00 3.03741940e-03 ... 2.09746475e-04\n",
      "  4.73688468e-02 3.53074741e+00]\n",
      " [6.53796941e-02 0.00000000e+00 6.77069474e-04 ... 6.51300866e-07\n",
      "  1.81231685e-02 3.40170026e+00]\n",
      " [5.05773947e-02 0.00000000e+00 2.75804719e-04 ... 8.81263230e-04\n",
      "  2.33331341e-02 3.22367764e+00]\n",
      " ...\n",
      " [2.92472802e-02 0.00000000e+00 2.18229034e-04 ... 1.38081814e-04\n",
      "  2.20862962e-02 3.19246483e+00]\n",
      " [4.41977233e-02 0.00000000e+00 2.68179749e-04 ... 2.72656005e-04\n",
      "  1.44368224e-02 3.50770473e+00]\n",
      " [2.86686961e-02 0.00000000e+00 3.39986844e-04 ... 4.08598548e-03\n",
      "  2.91077495e-02 3.13847542e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to store results for each model\n",
    "output_dict8 = {}\n",
    "\n",
    "# Loop over each model\n",
    "for model in models:\n",
    "    x_all = np.zeros((processed_grid_list[8].shape[0], model.num_features), dtype=float)\n",
    "\n",
    "    tic = time.time()\n",
    "    i = 0\n",
    "\n",
    "    # Iterate over each image in the dataloader\n",
    "    for images in dataloaders[8]:\n",
    "        for image in images:\n",
    "            if image is not None and image.shape[1] >= 0 and image.shape[2] >= 0:\n",
    "                image = image.to()\n",
    "                with torch.no_grad():\n",
    "                    feats = model(image.unsqueeze(0)).cpu().numpy()\n",
    "\n",
    "                x_all[i] = feats\n",
    "\n",
    "                if i % 1000 == 0:\n",
    "                    print(\n",
    "                        f\"{i}/{processed_grid_list[8].shape[0]} -- {i / processed_grid_list[8].shape[0] * 100:0.2f}%\"\n",
    "                        + f\" -- {time.time()-tic:0.2f} seconds\"\n",
    "                    )\n",
    "                    tic = time.time()\n",
    "\n",
    "                i += 1\n",
    "\n",
    "                # Check if i exceeds the number of points, break the loop\n",
    "                if i >= processed_grid_list[8].shape[0]:\n",
    "                    break\n",
    "\n",
    "        # Check if i exceeds the number of points, break the loop\n",
    "        if i >= processed_grid_list[8].shape[0]:\n",
    "            break\n",
    "\n",
    "    # Store x_all in the dictionary for the current model\n",
    "    output_dict8[model.num_features] = x_all\n",
    "\n",
    "# Access the results for each model\n",
    "for num_features, x_all in output_dict8.items():\n",
    "    print(f\"Results for model with {num_features} features:\")\n",
    "    print(x_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cd32f9ed-2f40-499c-9d90-47c3ca2078aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/120 -- 0.00% -- 3.73 seconds\n",
      "0/120 -- 0.00% -- 3.99 seconds\n",
      "0/120 -- 0.00% -- 4.28 seconds\n",
      "0/120 -- 0.00% -- 4.59 seconds\n",
      "Results for model with 100 features:\n",
      "[[0.         1.72146857 0.80521089 ... 5.04756451 0.09230165 4.68172455]\n",
      " [0.         1.84701061 0.87392282 ... 5.11611795 0.0684047  4.75493288]\n",
      " [0.         1.35743403 0.71657556 ... 4.76115561 0.08637787 4.40840626]\n",
      " ...\n",
      " [0.         1.33093262 0.67561001 ... 4.78017426 0.0967265  4.41284132]\n",
      " [0.         1.58849084 0.80054474 ... 5.02584839 0.07864507 4.6380868 ]\n",
      " [0.         1.36591625 0.73659801 ... 4.82998943 0.11043853 4.45337915]]\n",
      "Results for model with 500 features:\n",
      "[[5.06723905e-03 4.43257689e-01 1.03041548e-02 ... 3.80953908e+00\n",
      "  9.73991933e-04 2.79907298e+00]\n",
      " [1.43676577e-03 4.53069508e-01 5.18154493e-03 ... 3.92026091e+00\n",
      "  1.64197641e-04 2.84296417e+00]\n",
      " [1.24434635e-04 3.07752520e-01 5.76554623e-04 ... 3.48355961e+00\n",
      "  8.46213370e-04 2.70495224e+00]\n",
      " ...\n",
      " [1.93817104e-04 2.95960099e-01 6.08828559e-04 ... 3.46639895e+00\n",
      "  1.31198985e-03 2.69395423e+00]\n",
      " [2.08541358e-04 3.85259122e-01 1.02964859e-03 ... 3.70815587e+00\n",
      "  4.67676262e-04 2.80395651e+00]\n",
      " [2.60321656e-04 3.33751678e-01 8.58122541e-04 ... 3.49546599e+00\n",
      "  8.48229975e-03 2.72254896e+00]]\n",
      "Results for model with 1000 features:\n",
      "[[5.84628942e-05 0.00000000e+00 7.06936195e-02 ... 4.18613821e-01\n",
      "  7.80588016e-03 8.94020617e-01]\n",
      " [1.71803731e-05 0.00000000e+00 6.89284131e-02 ... 3.61945838e-01\n",
      "  1.24180480e-03 9.37467098e-01]\n",
      " [3.04904097e-06 0.00000000e+00 1.24657173e-02 ... 3.51508439e-01\n",
      "  2.62991246e-03 7.73820758e-01]\n",
      " ...\n",
      " [1.35500022e-05 0.00000000e+00 1.22895893e-02 ... 3.29364955e-01\n",
      "  4.94866259e-03 7.55183280e-01]\n",
      " [9.70827023e-06 0.00000000e+00 3.35553363e-02 ... 3.24474514e-01\n",
      "  1.53688865e-03 8.13868463e-01]\n",
      " [1.85909958e-05 0.00000000e+00 1.06825419e-02 ... 3.38697612e-01\n",
      "  1.22872619e-02 7.52055764e-01]]\n",
      "Results for model with 2000 features:\n",
      "[[1.25013545e-01 0.00000000e+00 3.18503077e-03 ... 1.56279275e-04\n",
      "  5.34885302e-02 3.50495028e+00]\n",
      " [7.85548538e-02 0.00000000e+00 9.10909090e-04 ... 1.73045828e-05\n",
      "  2.06665546e-02 3.51748157e+00]\n",
      " [3.95360887e-02 0.00000000e+00 1.26359388e-04 ... 3.67701374e-04\n",
      "  1.71398520e-02 3.15029407e+00]\n",
      " ...\n",
      " [2.96219550e-02 0.00000000e+00 1.56568771e-04 ... 2.15064894e-04\n",
      "  2.41466593e-02 3.22482562e+00]\n",
      " [4.27084304e-02 0.00000000e+00 3.46091751e-04 ... 6.38382189e-05\n",
      "  1.56648271e-02 3.39937234e+00]\n",
      " [2.87844539e-02 0.00000000e+00 2.98803818e-04 ... 5.52844908e-03\n",
      "  3.07058524e-02 3.21602750e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to store results for each model\n",
    "output_dict7 = {}\n",
    "\n",
    "# Loop over each model\n",
    "for model in models:\n",
    "    x_all = np.zeros((processed_grid_list[7].shape[0], model.num_features), dtype=float)\n",
    "\n",
    "    tic = time.time()\n",
    "    i = 0\n",
    "\n",
    "    # Iterate over each image in the dataloader\n",
    "    for images in dataloaders[7]:\n",
    "        for image in images:\n",
    "            if image is not None and image.shape[1] >= 0 and image.shape[2] >= 0:\n",
    "                image = image.to()\n",
    "                with torch.no_grad():\n",
    "                    feats = model(image.unsqueeze(0)).cpu().numpy()\n",
    "\n",
    "                x_all[i] = feats\n",
    "\n",
    "                if i % 1000 == 0:\n",
    "                    print(\n",
    "                        f\"{i}/{processed_grid_list[7].shape[0]} -- {i / processed_grid_list[7].shape[0] * 100:0.2f}%\"\n",
    "                        + f\" -- {time.time()-tic:0.2f} seconds\"\n",
    "                    )\n",
    "                    tic = time.time()\n",
    "\n",
    "                i += 1\n",
    "\n",
    "                # Check if i exceeds the number of points, break the loop\n",
    "                if i >= processed_grid_list[7].shape[0]:\n",
    "                    break\n",
    "\n",
    "        # Check if i exceeds the number of points, break the loop\n",
    "        if i >= processed_grid_list[7].shape[0]:\n",
    "            break\n",
    "\n",
    "    # Store x_all in the dictionary for the current model\n",
    "    output_dict7[model.num_features] = x_all\n",
    "\n",
    "# Access the results for each model\n",
    "for num_features, x_all in output_dict7.items():\n",
    "    print(f\"Results for model with {num_features} features:\")\n",
    "    print(x_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "53693928-f1b3-422a-9d48-3b5f3d74ad5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/168 -- 0.00% -- 3.85 seconds\n",
      "0/168 -- 0.00% -- 4.60 seconds\n",
      "0/168 -- 0.00% -- 4.86 seconds\n",
      "0/168 -- 0.00% -- 4.83 seconds\n",
      "Results for model with 100 features:\n",
      "[[0.         1.77366734 0.83869898 ... 5.12511396 0.08807686 4.75160551]\n",
      " [0.         1.92188537 0.90313524 ... 5.19471693 0.06666972 4.82874441]\n",
      " [0.         1.40932131 0.72052556 ... 4.77882528 0.08098996 4.42251015]\n",
      " ...\n",
      " [0.         1.33232999 0.69621897 ... 4.79089832 0.07945205 4.41193438]\n",
      " [0.         1.9413029  1.02299702 ... 5.47845268 0.06710782 5.06791735]\n",
      " [0.         1.6101377  0.90756166 ... 5.16988897 0.07912271 4.76398087]]\n",
      "Results for model with 500 features:\n",
      "[[5.50511619e-03 4.64015454e-01 1.13782752e-02 ... 3.86102843e+00\n",
      "  8.98728264e-04 2.82976246e+00]\n",
      " [1.77838979e-03 4.81901586e-01 6.27475092e-03 ... 3.99362111e+00\n",
      "  3.79243924e-04 2.87803650e+00]\n",
      " [4.25454520e-04 3.19728345e-01 1.69104885e-03 ... 3.52515268e+00\n",
      "  1.56813912e-04 2.70718145e+00]\n",
      " ...\n",
      " [1.21359073e-04 2.93782651e-01 4.85357712e-04 ... 3.47156119e+00\n",
      "  2.14222397e-04 2.70937753e+00]\n",
      " [4.64965909e-04 5.34503400e-01 9.62797494e-04 ... 4.06084251e+00\n",
      "  2.31271639e-04 3.01232290e+00]\n",
      " [6.54271105e-04 4.35179770e-01 1.43828965e-03 ... 3.74132204e+00\n",
      "  1.01653188e-02 2.88095403e+00]]\n",
      "Results for model with 1000 features:\n",
      "[[5.28521705e-05 0.00000000e+00 7.50004649e-02 ... 4.12591934e-01\n",
      "  8.14963412e-03 8.94082427e-01]\n",
      " [3.56422206e-05 0.00000000e+00 7.94503838e-02 ... 3.68889302e-01\n",
      "  1.92195259e-03 9.49584007e-01]\n",
      " [9.79587548e-06 0.00000000e+00 1.96213070e-02 ... 3.62076819e-01\n",
      "  1.32892351e-03 8.02872717e-01]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 1.25303920e-02 ... 3.24778020e-01\n",
      "  1.35702605e-03 7.53587306e-01]\n",
      " [1.14047180e-06 0.00000000e+00 4.89977412e-02 ... 2.95836955e-01\n",
      "  5.96405240e-04 8.29663038e-01]\n",
      " [6.07541142e-06 0.00000000e+00 1.71911139e-02 ... 3.03517729e-01\n",
      "  1.25918332e-02 7.50663340e-01]]\n",
      "Results for model with 2000 features:\n",
      "[[1.30527332e-01 0.00000000e+00 2.98664346e-03 ... 1.91443731e-04\n",
      "  5.46799190e-02 3.55539322e+00]\n",
      " [9.02090445e-02 0.00000000e+00 1.07767107e-03 ... 4.16278126e-05\n",
      "  2.03059278e-02 3.57956839e+00]\n",
      " [4.76857573e-02 0.00000000e+00 5.16854518e-04 ... 9.33042770e-07\n",
      "  2.13329755e-02 3.19858050e+00]\n",
      " ...\n",
      " [2.87736226e-02 0.00000000e+00 2.23124604e-04 ... 1.45905301e-06\n",
      "  1.39514105e-02 3.19638228e+00]\n",
      " [5.35616949e-02 0.00000000e+00 2.16746514e-04 ... 6.95782801e-05\n",
      "  9.30897146e-03 3.66475987e+00]\n",
      " [4.13369685e-02 0.00000000e+00 4.40779520e-04 ... 7.07931584e-03\n",
      "  2.62461286e-02 3.39603257e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to store results for each model\n",
    "output_dict6 = {}\n",
    "\n",
    "# Loop over each model\n",
    "for model in models:\n",
    "    x_all = np.zeros((processed_grid_list[6].shape[0], model.num_features), dtype=float)\n",
    "\n",
    "    tic = time.time()\n",
    "    i = 0\n",
    "\n",
    "    # Iterate over each image in the dataloader\n",
    "    for images in dataloaders[6]:\n",
    "        for image in images:\n",
    "            if image is not None and image.shape[1] >= 0 and image.shape[2] >= 0:\n",
    "                image = image.to()\n",
    "                with torch.no_grad():\n",
    "                    feats = model(image.unsqueeze(0)).cpu().numpy()\n",
    "\n",
    "                x_all[i] = feats\n",
    "\n",
    "                if i % 1000 == 0:\n",
    "                    print(\n",
    "                        f\"{i}/{processed_grid_list[6].shape[0]} -- {i / processed_grid_list[6].shape[0] * 100:0.2f}%\"\n",
    "                        + f\" -- {time.time()-tic:0.2f} seconds\"\n",
    "                    )\n",
    "                    tic = time.time()\n",
    "\n",
    "                i += 1\n",
    "\n",
    "                # Check if i exceeds the number of points, break the loop\n",
    "                if i >= processed_grid_list[6].shape[0]:\n",
    "                    break\n",
    "\n",
    "        # Check if i exceeds the number of points, break the loop\n",
    "        if i >= processed_grid_list[6].shape[0]:\n",
    "            break\n",
    "\n",
    "    # Store x_all in the dictionary for the current model\n",
    "    output_dict6[model.num_features] = x_all\n",
    "\n",
    "# Access the results for each model\n",
    "for num_features, x_all in output_dict6.items():\n",
    "    print(f\"Results for model with {num_features} features:\")\n",
    "    print(x_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4fb3f206-ab39-4bae-baa7-55cb6fec6fb9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/238 -- 0.00% -- 4.83 seconds\n",
      "0/238 -- 0.00% -- 4.93 seconds\n",
      "0/238 -- 0.00% -- 4.93 seconds\n",
      "0/238 -- 0.00% -- 5.16 seconds\n",
      "Results for model with 100 features:\n",
      "[[0.         1.82534957 0.88032842 ... 5.22850657 0.08194213 4.84075117]\n",
      " [0.         1.73868668 0.82147884 ... 5.06010675 0.07840274 4.69467783]\n",
      " [0.         1.56838751 0.69791359 ... 4.66540861 0.09817983 4.3548913 ]\n",
      " ...\n",
      " [0.         1.83608627 0.91913772 ... 5.22769165 0.07325838 4.83504963]\n",
      " [0.         1.8818953  1.08477473 ... 5.68228006 0.0774403  5.21878624]\n",
      " [0.         1.39062345 0.75789297 ... 4.92128372 0.07619312 4.53097343]]\n",
      "Results for model with 500 features:\n",
      "[[6.04916736e-03 4.86535251e-01 1.10166296e-02 ... 3.92038274e+00\n",
      "  9.51347873e-04 2.87560987e+00]\n",
      " [1.56593416e-03 4.28456187e-01 6.08962728e-03 ... 3.82851434e+00\n",
      "  6.31139730e-04 2.81587887e+00]\n",
      " [1.59179792e-03 3.45585555e-01 4.96854167e-03 ... 3.62450385e+00\n",
      "  2.49328295e-04 2.64537501e+00]\n",
      " ...\n",
      " [4.81503957e-04 4.73937809e-01 1.22379733e-03 ... 3.93449378e+00\n",
      "  1.63976132e-04 2.89835334e+00]\n",
      " [2.50740239e-04 5.71757674e-01 9.12750256e-04 ... 4.04309464e+00\n",
      "  1.42717576e-02 3.09754539e+00]\n",
      " [1.58988361e-04 3.25549722e-01 7.13426038e-04 ... 3.53708911e+00\n",
      "  5.39193046e-04 2.76628590e+00]]\n",
      "Results for model with 1000 features:\n",
      "[[5.88730327e-05 0.00000000e+00 7.44648427e-02 ... 3.93374652e-01\n",
      "  7.52732717e-03 8.81428301e-01]\n",
      " [4.73030414e-05 0.00000000e+00 6.27244562e-02 ... 3.82310987e-01\n",
      "  4.04050853e-03 8.94054413e-01]\n",
      " [2.14376105e-05 0.00000000e+00 6.22847527e-02 ... 4.22837377e-01\n",
      "  2.02301773e-03 9.59707379e-01]\n",
      " ...\n",
      " [5.72655949e-07 0.00000000e+00 5.67353144e-02 ... 3.22905838e-01\n",
      "  7.31111970e-04 8.78669322e-01]\n",
      " [4.62947219e-06 0.00000000e+00 1.66573264e-02 ... 2.63532072e-01\n",
      "  1.68459285e-02 6.94882452e-01]\n",
      " [5.05595472e-06 0.00000000e+00 8.74000508e-03 ... 3.03222269e-01\n",
      "  1.86879875e-03 7.28956580e-01]]\n",
      "Results for model with 2000 features:\n",
      "[[1.27469897e-01 0.00000000e+00 3.10883019e-03 ... 1.73704946e-04\n",
      "  4.76891398e-02 3.61086392e+00]\n",
      " [9.02941376e-02 0.00000000e+00 1.17235584e-03 ... 1.29751890e-04\n",
      "  2.88457926e-02 3.47972441e+00]\n",
      " [7.17674717e-02 0.00000000e+00 1.09026476e-03 ... 1.32641139e-06\n",
      "  3.40447314e-02 3.23612738e+00]\n",
      " ...\n",
      " [5.64353466e-02 0.00000000e+00 2.69151438e-04 ... 1.66054779e-05\n",
      "  1.28789227e-02 3.54341936e+00]\n",
      " [4.29764204e-02 0.00000000e+00 3.36787693e-04 ... 1.00507950e-02\n",
      "  2.89243571e-02 3.73268986e+00]\n",
      " [2.59617232e-02 0.00000000e+00 9.72466223e-05 ... 8.90768351e-05\n",
      "  1.10273696e-02 3.25710392e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to store results for each model\n",
    "output_dict5 = {}\n",
    "\n",
    "# Loop over each model\n",
    "for model in models:\n",
    "    x_all = np.zeros((processed_grid_list[5].shape[0], model.num_features), dtype=float)\n",
    "\n",
    "    tic = time.time()\n",
    "    i = 0\n",
    "\n",
    "    # Iterate over each image in the dataloader\n",
    "    for images in dataloaders[5]:\n",
    "        for image in images:\n",
    "            if image is not None and image.shape[1] >= 0 and image.shape[2] >= 0:\n",
    "                image = image.to()\n",
    "                with torch.no_grad():\n",
    "                    feats = model(image.unsqueeze(0)).cpu().numpy()\n",
    "\n",
    "                x_all[i] = feats\n",
    "\n",
    "                if i % 1000 == 0:\n",
    "                    print(\n",
    "                        f\"{i}/{processed_grid_list[5].shape[0]} -- {i / processed_grid_list[5].shape[0] * 100:0.2f}%\"\n",
    "                        + f\" -- {time.time()-tic:0.2f} seconds\"\n",
    "                    )\n",
    "                    tic = time.time()\n",
    "\n",
    "                i += 1\n",
    "\n",
    "                # Check if i exceeds the number of points, break the loop\n",
    "                if i >= processed_grid_list[5].shape[0]:\n",
    "                    break\n",
    "\n",
    "        # Check if i exceeds the number of points, break the loop\n",
    "        if i >= processed_grid_list[5].shape[0]:\n",
    "            break\n",
    "\n",
    "    # Store x_all in the dictionary for the current model\n",
    "    output_dict5[model.num_features] = x_all\n",
    "\n",
    "# Access the results for each model\n",
    "for num_features, x_all in output_dict5.items():\n",
    "    print(f\"Results for model with {num_features} features:\")\n",
    "    print(x_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "85cb2377-8d20-469b-9549-caf35834bb12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/378 -- 0.00% -- 4.45 seconds\n",
      "0/378 -- 0.00% -- 4.87 seconds\n",
      "0/378 -- 0.00% -- 6.12 seconds\n",
      "0/378 -- 0.00% -- 5.70 seconds\n",
      "Results for model with 100 features:\n",
      "[[0.         1.81773102 0.88747257 ... 5.23759794 0.08180258 4.84602213]\n",
      " [0.         1.87970054 0.8854754  ... 5.19445276 0.07444501 4.82658148]\n",
      " [0.         1.96186304 0.90993077 ... 5.17710638 0.07064674 4.83210707]\n",
      " ...\n",
      " [0.         1.92412364 0.97272497 ... 5.18384409 0.0904038  4.84477186]\n",
      " [0.         1.60411429 0.82987916 ... 5.03209591 0.08754791 4.65120935]\n",
      " [0.         1.54888833 0.83338022 ... 4.85064554 0.04282106 4.5189085 ]]\n",
      "Results for model with 500 features:\n",
      "[[6.77983742e-03 4.86570358e-01 1.10856593e-02 ... 3.91488910e+00\n",
      "  1.26336433e-03 2.88220024e+00]\n",
      " [1.82556501e-03 4.85809118e-01 7.39659695e-03 ... 3.96224642e+00\n",
      "  8.13114690e-04 2.87584901e+00]\n",
      " [2.10330449e-03 4.86897230e-01 6.62286114e-03 ... 4.02280998e+00\n",
      "  7.57150337e-05 2.87244892e+00]\n",
      " ...\n",
      " [9.01787658e-04 5.05864203e-01 1.15317723e-03 ... 3.99578905e+00\n",
      "  3.19383864e-04 2.89891791e+00]\n",
      " [1.39978551e-03 4.12194699e-01 3.23230401e-03 ... 3.72103333e+00\n",
      "  4.20365977e-05 2.82196712e+00]\n",
      " [2.17741705e-04 3.48798782e-01 4.69203864e-04 ... 3.64642906e+00\n",
      "  0.00000000e+00 2.76855755e+00]]\n",
      "Results for model with 1000 features:\n",
      "[[8.68097923e-05 0.00000000e+00 7.20491186e-02 ... 3.86409104e-01\n",
      "  8.72064568e-03 8.68852913e-01]\n",
      " [2.03936797e-05 0.00000000e+00 7.13475049e-02 ... 3.92469615e-01\n",
      "  6.54654577e-03 9.22896743e-01]\n",
      " [1.88074118e-05 0.00000000e+00 9.57539827e-02 ... 3.76058728e-01\n",
      "  2.48694589e-04 9.80147362e-01]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 7.53096417e-02 ... 3.40790600e-01\n",
      "  1.67894247e-03 9.41192150e-01]\n",
      " [0.00000000e+00 0.00000000e+00 3.53783444e-02 ... 3.49348277e-01\n",
      "  6.83297054e-04 8.16007376e-01]\n",
      " [0.00000000e+00 0.00000000e+00 1.31183462e-02 ... 3.27536702e-01\n",
      "  4.39416654e-05 8.41094911e-01]]\n",
      "Results for model with 2000 features:\n",
      "[[1.20495863e-01 0.00000000e+00 2.70403433e-03 ... 2.48436379e-04\n",
      "  4.70203720e-02 3.60172248e+00]\n",
      " [1.09157585e-01 0.00000000e+00 1.89288880e-03 ... 1.36960502e-04\n",
      "  4.11781855e-02 3.59171224e+00]\n",
      " [9.37567279e-02 0.00000000e+00 7.89797283e-04 ... 0.00000000e+00\n",
      "  1.51204923e-02 3.57516456e+00]\n",
      " ...\n",
      " [5.43091260e-02 0.00000000e+00 1.17721960e-04 ... 5.74315600e-05\n",
      "  1.95138454e-02 3.47785664e+00]\n",
      " [6.19641468e-02 0.00000000e+00 7.74452346e-04 ... 0.00000000e+00\n",
      "  1.73001233e-02 3.36440897e+00]\n",
      " [2.99553908e-02 0.00000000e+00 3.93433984e-05 ... 0.00000000e+00\n",
      "  9.17152502e-03 3.16175842e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to store results for each model\n",
    "output_dict4 = {}\n",
    "\n",
    "# Loop over each model\n",
    "for model in models:\n",
    "    x_all = np.zeros((processed_grid_list[4].shape[0], model.num_features), dtype=float)\n",
    "\n",
    "    tic = time.time()\n",
    "    i = 0\n",
    "\n",
    "    # Iterate over each image in the dataloader\n",
    "    for images in dataloaders[4]:\n",
    "        for image in images:\n",
    "            if image is not None and image.shape[1] >= 0 and image.shape[2] >= 0:\n",
    "                image = image.to()\n",
    "                with torch.no_grad():\n",
    "                    feats = model(image.unsqueeze(0)).cpu().numpy()\n",
    "\n",
    "                x_all[i] = feats\n",
    "\n",
    "                if i % 1000 == 0:\n",
    "                    print(\n",
    "                        f\"{i}/{processed_grid_list[4].shape[0]} -- {i / processed_grid_list[4].shape[0] * 100:0.2f}%\"\n",
    "                        + f\" -- {time.time()-tic:0.2f} seconds\"\n",
    "                    )\n",
    "                    tic = time.time()\n",
    "\n",
    "                i += 1\n",
    "\n",
    "                # Check if i exceeds the number of points, break the loop\n",
    "                if i >= processed_grid_list[4].shape[0]:\n",
    "                    break\n",
    "\n",
    "        # Check if i exceeds the number of points, break the loop\n",
    "        if i >= processed_grid_list[4].shape[0]:\n",
    "            break\n",
    "\n",
    "    # Store x_all in the dictionary for the current model\n",
    "    output_dict4[model.num_features] = x_all\n",
    "\n",
    "# Access the results for each model\n",
    "for num_features, x_all in output_dict4.items():\n",
    "    print(f\"Results for model with {num_features} features:\")\n",
    "    print(x_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "940e6b6e-7199-49a9-aa6a-267a98e07c99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/672 -- 0.00% -- 4.32 seconds\n",
      "0/672 -- 0.00% -- 5.62 seconds\n",
      "0/672 -- 0.00% -- 5.96 seconds\n",
      "0/672 -- 0.00% -- 5.96 seconds\n",
      "Results for model with 100 features:\n",
      "[[0.         1.92121243 0.95775342 ... 5.36362028 0.06805428 4.9663372 ]\n",
      " [0.         1.76122701 0.83530915 ... 5.08644485 0.09002601 4.72175026]\n",
      " [0.         1.8949815  0.91027963 ... 5.26403046 0.0585848  4.89139128]\n",
      " ...\n",
      " [0.         1.76686108 1.00851607 ... 5.45590544 0.05900662 5.02705288]\n",
      " [0.         1.43231273 0.76554483 ... 4.69423962 0.06514923 4.36766052]\n",
      " [0.         1.51728988 0.84695292 ... 4.96696711 0.04397885 4.58829212]]\n",
      "Results for model with 500 features:\n",
      "[[2.12762691e-03 5.19280076e-01 1.11057237e-02 ... 4.01484776e+00\n",
      "  6.43840351e-04 2.94015813e+00]\n",
      " [6.49107620e-03 4.56138551e-01 7.69801391e-03 ... 3.84628820e+00\n",
      "  1.98019529e-03 2.82237315e+00]\n",
      " [2.32658247e-04 4.73465025e-01 6.22392399e-03 ... 3.98867464e+00\n",
      "  1.22071811e-04 2.90649009e+00]\n",
      " ...\n",
      " [4.23768040e-04 4.97599721e-01 2.48352904e-03 ... 3.92464232e+00\n",
      "  0.00000000e+00 3.01663065e+00]\n",
      " [5.58663596e-05 3.11834931e-01 5.00706839e-04 ... 3.52188158e+00\n",
      "  2.82570487e-04 2.68483448e+00]\n",
      " [3.93478433e-04 3.59657735e-01 3.75634030e-04 ... 3.64327383e+00\n",
      "  4.21522782e-06 2.80923533e+00]]\n",
      "Results for model with 1000 features:\n",
      "[[6.66976775e-05 0.00000000e+00 7.49586821e-02 ... 3.58001918e-01\n",
      "  5.81079349e-03 8.75769854e-01]\n",
      " [3.32216587e-06 0.00000000e+00 6.59008175e-02 ... 4.09509033e-01\n",
      "  1.23732081e-02 8.95991743e-01]\n",
      " [2.46835480e-05 0.00000000e+00 7.59553388e-02 ... 3.49871397e-01\n",
      "  7.49998318e-04 9.00354624e-01]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 3.30583416e-02 ... 2.71669000e-01\n",
      "  1.52400753e-06 7.24835873e-01]\n",
      " [0.00000000e+00 0.00000000e+00 1.33327115e-02 ... 3.51234734e-01\n",
      "  1.28675299e-03 8.48000526e-01]\n",
      " [0.00000000e+00 0.00000000e+00 1.57332849e-02 ... 3.05369377e-01\n",
      "  5.68735159e-05 7.77593136e-01]]\n",
      "Results for model with 2000 features:\n",
      "[[1.17423937e-01 0.00000000e+00 2.67018238e-03 ... 2.99949519e-04\n",
      "  3.80361639e-02 3.66038680e+00]\n",
      " [1.19666293e-01 0.00000000e+00 2.81628920e-03 ... 1.76005837e-04\n",
      "  5.68832494e-02 3.51509905e+00]\n",
      " [8.62066448e-02 0.00000000e+00 5.71525889e-04 ... 0.00000000e+00\n",
      "  1.34227611e-02 3.60384440e+00]\n",
      " ...\n",
      " [5.81851676e-02 0.00000000e+00 2.03864067e-04 ... 0.00000000e+00\n",
      "  5.88331837e-03 3.55683279e+00]\n",
      " [3.20380330e-02 0.00000000e+00 7.48774619e-05 ... 9.24100823e-06\n",
      "  1.38301738e-02 3.07790685e+00]\n",
      " [3.72181013e-02 0.00000000e+00 3.17968137e-04 ... 0.00000000e+00\n",
      "  7.26501876e-03 3.23300481e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to store results for each model\n",
    "output_dict3 = {}\n",
    "\n",
    "# Loop over each model\n",
    "for model in models:\n",
    "    x_all = np.zeros((processed_grid_list[3].shape[0], model.num_features), dtype=float)\n",
    "\n",
    "    tic = time.time()\n",
    "    i = 0\n",
    "\n",
    "    # Iterate over each image in the dataloader\n",
    "    for images in dataloaders[3]:\n",
    "        for image in images:\n",
    "            if image is not None and image.shape[1] >= 0 and image.shape[2] >= 0:\n",
    "                image = image.to()\n",
    "                with torch.no_grad():\n",
    "                    feats = model(image.unsqueeze(0)).cpu().numpy()\n",
    "\n",
    "                x_all[i] = feats\n",
    "\n",
    "                if i % 1000 == 0:\n",
    "                    print(\n",
    "                        f\"{i}/{processed_grid_list[3].shape[0]} -- {i / processed_grid_list[3].shape[0] * 100:0.2f}%\"\n",
    "                        + f\" -- {time.time()-tic:0.2f} seconds\"\n",
    "                    )\n",
    "                    tic = time.time()\n",
    "\n",
    "                i += 1\n",
    "\n",
    "                # Check if i exceeds the number of points, break the loop\n",
    "                if i >= processed_grid_list[3].shape[0]:\n",
    "                    break\n",
    "\n",
    "        # Check if i exceeds the number of points, break the loop\n",
    "        if i >= processed_grid_list[3].shape[0]:\n",
    "            break\n",
    "\n",
    "    # Store x_all in the dictionary for the current model\n",
    "    output_dict3[model.num_features] = x_all\n",
    "\n",
    "# Access the results for each model\n",
    "for num_features, x_all in output_dict3.items():\n",
    "    print(f\"Results for model with {num_features} features:\")\n",
    "    print(x_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "00f8da94-c737-437b-8ad3-cb16b2795d75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/1360 -- 0.00% -- 4.82 seconds\n",
      "1000/1360 -- 73.53% -- 10.52 seconds\n",
      "0/1360 -- 0.00% -- 4.98 seconds\n",
      "1000/1360 -- 73.53% -- 13.66 seconds\n",
      "0/1360 -- 0.00% -- 4.57 seconds\n",
      "1000/1360 -- 73.53% -- 25.08 seconds\n",
      "0/1360 -- 0.00% -- 4.60 seconds\n",
      "1000/1360 -- 73.53% -- 40.79 seconds\n",
      "Results for model with 100 features:\n",
      "[[0.         1.76099789 0.92768496 ... 5.34167767 0.06672831 4.93575525]\n",
      " [0.         1.7409023  0.87958747 ... 5.27623558 0.07124543 4.87951565]\n",
      " [0.         1.92570937 0.91790628 ... 5.24346352 0.06450409 4.86399555]\n",
      " ...\n",
      " [0.         2.00502634 1.02688169 ... 5.46041203 0.05147639 5.04372072]\n",
      " [0.         1.26115501 0.65220362 ... 4.22550583 0.05613609 3.98517537]\n",
      " [0.         1.57442701 0.86556101 ... 4.99746609 0.03175849 4.61234617]]\n",
      "Results for model with 500 features:\n",
      "[[1.55125943e-03 4.77706432e-01 5.31995622e-03 ... 3.89117670e+00\n",
      "  8.49495875e-04 2.93736243e+00]\n",
      " [1.04227727e-02 4.68618006e-01 3.34559707e-03 ... 3.86562133e+00\n",
      "  5.62579371e-04 2.90535665e+00]\n",
      " [1.29116268e-03 4.97523963e-01 7.49815442e-03 ... 4.00301647e+00\n",
      "  8.73813522e-04 2.89797640e+00]\n",
      " ...\n",
      " [1.65806280e-03 5.44042289e-01 4.52631200e-03 ... 4.10484838e+00\n",
      "  6.50198272e-05 3.00348282e+00]\n",
      " [0.00000000e+00 1.95793718e-01 3.54721094e-04 ... 3.30338073e+00\n",
      "  0.00000000e+00 2.49948597e+00]\n",
      " [6.00491301e-04 3.71377826e-01 2.42627124e-04 ... 3.69508195e+00\n",
      "  0.00000000e+00 2.82582784e+00]]\n",
      "Results for model with 1000 features:\n",
      "[[4.82900141e-05 0.00000000e+00 4.73309197e-02 ... 3.25863808e-01\n",
      "  6.04003295e-03 7.75147736e-01]\n",
      " [0.00000000e+00 0.00000000e+00 5.79968281e-02 ... 3.80069613e-01\n",
      "  7.01210322e-03 7.95977056e-01]\n",
      " [0.00000000e+00 0.00000000e+00 6.34714812e-02 ... 3.74793440e-01\n",
      "  4.72419150e-03 9.30268347e-01]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 6.03662319e-02 ... 3.17027599e-01\n",
      "  3.32451804e-04 8.84268880e-01]\n",
      " [0.00000000e+00 0.00000000e+00 4.49084444e-03 ... 3.90354067e-01\n",
      "  4.32703309e-05 9.36269879e-01]\n",
      " [0.00000000e+00 0.00000000e+00 2.07380261e-02 ... 3.14529359e-01\n",
      "  1.94495333e-05 8.01813722e-01]]\n",
      "Results for model with 2000 features:\n",
      "[[9.15890560e-02 0.00000000e+00 1.81983749e-03 ... 4.23647318e-04\n",
      "  3.27062868e-02 3.58096480e+00]\n",
      " [1.21363178e-01 0.00000000e+00 2.60400586e-03 ... 2.12298895e-04\n",
      "  4.26341556e-02 3.58227539e+00]\n",
      " [1.06393717e-01 0.00000000e+00 1.93643966e-03 ... 1.59909745e-04\n",
      "  3.55452858e-02 3.61641860e+00]\n",
      " ...\n",
      " [8.87835771e-02 0.00000000e+00 1.13821262e-03 ... 0.00000000e+00\n",
      "  9.52789001e-03 3.68356609e+00]\n",
      " [1.30386427e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  9.48156230e-03 2.73594713e+00]\n",
      " [4.87620644e-02 0.00000000e+00 6.16094156e-04 ... 0.00000000e+00\n",
      "  8.84964783e-03 3.26517963e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to store results for each model\n",
    "output_dict2 = {}\n",
    "\n",
    "# Loop over each model\n",
    "for model in models:\n",
    "    x_all = np.zeros((processed_grid_list[2].shape[0], model.num_features), dtype=float)\n",
    "\n",
    "    tic = time.time()\n",
    "    i = 0\n",
    "\n",
    "    # Iterate over each image in the dataloader\n",
    "    for images in dataloaders[2]:\n",
    "        for image in images:\n",
    "            if image is not None and image.shape[1] >= 0 and image.shape[2] >= 0:\n",
    "                image = image.to()\n",
    "                with torch.no_grad():\n",
    "                    feats = model(image.unsqueeze(0)).cpu().numpy()\n",
    "\n",
    "                x_all[i] = feats\n",
    "\n",
    "                if i % 1000 == 0:\n",
    "                    print(\n",
    "                        f\"{i}/{processed_grid_list[2].shape[0]} -- {i / processed_grid_list[2].shape[0] * 100:0.2f}%\"\n",
    "                        + f\" -- {time.time()-tic:0.2f} seconds\"\n",
    "                    )\n",
    "                    tic = time.time()\n",
    "\n",
    "                i += 1\n",
    "\n",
    "                # Check if i exceeds the number of points, break the loop\n",
    "                if i >= processed_grid_list[2].shape[0]:\n",
    "                    break\n",
    "\n",
    "        # Check if i exceeds the number of points, break the loop\n",
    "        if i >= processed_grid_list[2].shape[0]:\n",
    "            break\n",
    "\n",
    "    # Store x_all in the dictionary for the current model\n",
    "    output_dict2[model.num_features] = x_all\n",
    "\n",
    "# Access the results for each model\n",
    "for num_features, x_all in output_dict2.items():\n",
    "    print(f\"Results for model with {num_features} features:\")\n",
    "    print(x_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3aebc6f7-2304-4e5f-a82d-965f309dbab7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/4526 -- 0.00% -- 5.13 seconds\n",
      "1000/4526 -- 22.09% -- 8.68 seconds\n",
      "2000/4526 -- 44.19% -- 7.24 seconds\n",
      "3000/4526 -- 66.28% -- 7.62 seconds\n",
      "4000/4526 -- 88.38% -- 6.81 seconds\n",
      "0/4526 -- 0.00% -- 4.06 seconds\n",
      "1000/4526 -- 22.09% -- 9.36 seconds\n",
      "2000/4526 -- 44.19% -- 8.85 seconds\n",
      "3000/4526 -- 66.28% -- 7.65 seconds\n",
      "4000/4526 -- 88.38% -- 7.58 seconds\n",
      "0/4526 -- 0.00% -- 4.77 seconds\n",
      "1000/4526 -- 22.09% -- 11.03 seconds\n",
      "2000/4526 -- 44.19% -- 11.93 seconds\n",
      "3000/4526 -- 66.28% -- 8.94 seconds\n",
      "4000/4526 -- 88.38% -- 9.85 seconds\n",
      "0/4526 -- 0.00% -- 4.78 seconds\n",
      "1000/4526 -- 22.09% -- 15.48 seconds\n",
      "2000/4526 -- 44.19% -- 15.41 seconds\n",
      "3000/4526 -- 66.28% -- 15.44 seconds\n",
      "4000/4526 -- 88.38% -- 15.27 seconds\n",
      "Results for model with 100 features:\n",
      "[[0.         1.62965119 0.90413731 ... 5.45652533 0.04250801 4.98189735]\n",
      " [0.         1.59969854 1.03635263 ... 5.38228083 0.04110231 4.97291756]\n",
      " [0.         1.75458694 0.96645612 ... 5.60029602 0.04903146 5.13469172]\n",
      " ...\n",
      " [0.         1.34001005 0.7325626  ... 4.77261639 0.07280169 4.38933372]\n",
      " [0.         1.72688556 0.9935329  ... 5.29903173 0.02972736 4.92200756]\n",
      " [0.         1.27229226 0.68564588 ... 4.67351627 0.07751986 4.3080554 ]]\n",
      "Results for model with 500 features:\n",
      "[[2.31672544e-04 4.28698689e-01 1.16492365e-03 ... 3.80300999e+00\n",
      "  4.58035094e-04 2.96048665e+00]\n",
      " [0.00000000e+00 4.63819712e-01 2.26336633e-04 ... 3.77635479e+00\n",
      "  0.00000000e+00 3.00667500e+00]\n",
      " [2.26279106e-02 5.17171443e-01 1.61458680e-03 ... 3.93989611e+00\n",
      "  1.87568599e-04 3.06569958e+00]\n",
      " ...\n",
      " [6.91376510e-04 3.16482186e-01 4.25118487e-04 ... 3.48547029e+00\n",
      "  0.00000000e+00 2.75257659e+00]\n",
      " [2.28817837e-04 4.45497453e-01 0.00000000e+00 ... 3.85948086e+00\n",
      "  0.00000000e+00 2.94386292e+00]\n",
      " [0.00000000e+00 2.67039418e-01 6.90780071e-05 ... 3.39704013e+00\n",
      "  2.20865986e-05 2.65998554e+00]]\n",
      "Results for model with 1000 features:\n",
      "[[9.18568112e-05 0.00000000e+00 1.86678097e-02 ... 2.50018686e-01\n",
      "  2.82223779e-03 6.59269452e-01]\n",
      " [0.00000000e+00 0.00000000e+00 1.08939987e-02 ... 2.72392899e-01\n",
      "  9.75529110e-05 6.30792320e-01]\n",
      " [0.00000000e+00 0.00000000e+00 5.40288836e-02 ... 3.45825493e-01\n",
      "  2.57044449e-03 6.36850417e-01]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 8.48907232e-03 ... 3.46190572e-01\n",
      "  4.44332138e-04 7.38286018e-01]\n",
      " [0.00000000e+00 0.00000000e+00 2.88824234e-02 ... 2.65190899e-01\n",
      "  0.00000000e+00 7.62283623e-01]\n",
      " [0.00000000e+00 0.00000000e+00 4.28836560e-03 ... 3.22010040e-01\n",
      "  3.11153766e-04 7.62679160e-01]]\n",
      "Results for model with 2000 features:\n",
      "[[5.34569100e-02 0.00000000e+00 6.81421370e-04 ... 2.06829664e-05\n",
      "  2.03845985e-02 3.62866306e+00]\n",
      " [4.92603891e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  9.36621241e-03 3.34251642e+00]\n",
      " [1.29314557e-01 0.00000000e+00 2.17017066e-03 ... 7.83992800e-05\n",
      "  2.61659529e-02 3.70084476e+00]\n",
      " ...\n",
      " [2.56259013e-02 0.00000000e+00 5.34137536e-04 ... 0.00000000e+00\n",
      "  1.88284665e-02 3.11421394e+00]\n",
      " [5.96349165e-02 0.00000000e+00 4.20229509e-04 ... 0.00000000e+00\n",
      "  5.34467399e-03 3.43009901e+00]\n",
      " [2.06810758e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  1.17682442e-02 3.08048439e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to store results for each model\n",
    "output_dict1 = {}\n",
    "\n",
    "# Loop over each model\n",
    "for model in models:\n",
    "    x_all = np.zeros((processed_grid_list[1].shape[0], model.num_features), dtype=float)\n",
    "\n",
    "    tic = time.time()\n",
    "    i = 0\n",
    "\n",
    "    # Iterate over each image in the dataloader\n",
    "    for images in dataloaders[1]:\n",
    "        for image in images:\n",
    "            if image is not None and image.shape[1] >= 0 and image.shape[2] >= 0:\n",
    "                image = image.to()\n",
    "                with torch.no_grad():\n",
    "                    feats = model(image.unsqueeze(0)).cpu().numpy()\n",
    "\n",
    "                x_all[i] = feats\n",
    "\n",
    "                if i % 1000 == 0:\n",
    "                    print(\n",
    "                        f\"{i}/{processed_grid_list[1].shape[0]} -- {i / processed_grid_list[1].shape[0] * 100:0.2f}%\"\n",
    "                        + f\" -- {time.time()-tic:0.2f} seconds\"\n",
    "                    )\n",
    "                    tic = time.time()\n",
    "\n",
    "                i += 1\n",
    "\n",
    "                # Check if i exceeds the number of points, break the loop\n",
    "                if i >= processed_grid_list[1].shape[0]:\n",
    "                    break\n",
    "\n",
    "        # Check if i exceeds the number of points, break the loop\n",
    "        if i >= processed_grid_list[1].shape[0]:\n",
    "            break\n",
    "\n",
    "    # Store x_all in the dictionary for the current model\n",
    "    output_dict1[model.num_features] = x_all\n",
    "\n",
    "# Access the results for each model\n",
    "for num_features, x_all in output_dict1.items():\n",
    "    print(f\"Results for model with {num_features} features:\")\n",
    "    print(x_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e9837773-aac7-4dda-ba98-514109cb6ead",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/12688 -- 0.00% -- 3.73 seconds\n",
      "1000/12688 -- 7.88% -- 8.05 seconds\n",
      "2000/12688 -- 15.76% -- 6.05 seconds\n",
      "3000/12688 -- 23.64% -- 7.14 seconds\n",
      "4000/12688 -- 31.53% -- 6.79 seconds\n",
      "5000/12688 -- 39.41% -- 6.57 seconds\n",
      "6000/12688 -- 47.29% -- 5.49 seconds\n",
      "7000/12688 -- 55.17% -- 6.87 seconds\n",
      "8000/12688 -- 63.05% -- 6.28 seconds\n",
      "9000/12688 -- 70.93% -- 6.42 seconds\n",
      "10000/12688 -- 78.81% -- 6.56 seconds\n",
      "11000/12688 -- 86.70% -- 6.29 seconds\n",
      "12000/12688 -- 94.58% -- 5.88 seconds\n",
      "0/12688 -- 0.00% -- 4.40 seconds\n",
      "1000/12688 -- 7.88% -- 7.58 seconds\n",
      "2000/12688 -- 15.76% -- 7.42 seconds\n",
      "3000/12688 -- 23.64% -- 8.08 seconds\n",
      "4000/12688 -- 31.53% -- 7.58 seconds\n",
      "5000/12688 -- 39.41% -- 7.15 seconds\n",
      "6000/12688 -- 47.29% -- 6.41 seconds\n",
      "7000/12688 -- 55.17% -- 7.79 seconds\n",
      "8000/12688 -- 63.05% -- 6.96 seconds\n",
      "9000/12688 -- 70.93% -- 6.85 seconds\n",
      "10000/12688 -- 78.81% -- 6.37 seconds\n",
      "11000/12688 -- 86.70% -- 8.38 seconds\n",
      "12000/12688 -- 94.58% -- 7.66 seconds\n",
      "0/12688 -- 0.00% -- 4.47 seconds\n",
      "1000/12688 -- 7.88% -- 8.05 seconds\n",
      "2000/12688 -- 15.76% -- 6.65 seconds\n",
      "3000/12688 -- 23.64% -- 7.38 seconds\n",
      "4000/12688 -- 31.53% -- 7.72 seconds\n",
      "5000/12688 -- 39.41% -- 7.37 seconds\n",
      "6000/12688 -- 47.29% -- 6.87 seconds\n",
      "7000/12688 -- 55.17% -- 7.81 seconds\n",
      "8000/12688 -- 63.05% -- 6.57 seconds\n",
      "9000/12688 -- 70.93% -- 8.13 seconds\n",
      "10000/12688 -- 78.81% -- 7.36 seconds\n",
      "11000/12688 -- 86.70% -- 7.19 seconds\n",
      "12000/12688 -- 94.58% -- 7.57 seconds\n",
      "0/12688 -- 0.00% -- 4.28 seconds\n",
      "1000/12688 -- 7.88% -- 9.90 seconds\n",
      "2000/12688 -- 15.76% -- 8.26 seconds\n",
      "3000/12688 -- 23.64% -- 8.20 seconds\n",
      "4000/12688 -- 31.53% -- 7.28 seconds\n",
      "5000/12688 -- 39.41% -- 8.50 seconds\n",
      "6000/12688 -- 47.29% -- 8.18 seconds\n",
      "7000/12688 -- 55.17% -- 7.74 seconds\n",
      "8000/12688 -- 63.05% -- 7.29 seconds\n",
      "9000/12688 -- 70.93% -- 9.17 seconds\n",
      "10000/12688 -- 78.81% -- 8.68 seconds\n",
      "11000/12688 -- 86.70% -- 7.93 seconds\n",
      "12000/12688 -- 94.58% -- 7.24 seconds\n",
      "Results for model with 100 features:\n",
      "[[0.         1.73622167 1.06634486 ... 6.21360302 0.00946036 5.64965487]\n",
      " [0.         1.55215335 0.89197254 ... 5.0370841  0.0186793  4.67064857]\n",
      " [0.         1.54536068 1.07538593 ... 5.40754128 0.02346952 4.96724272]\n",
      " ...\n",
      " [0.         1.62183464 0.96905077 ... 4.99714518 0.02693368 4.64291525]\n",
      " [0.         2.1219852  1.22915947 ... 5.93612003 0.00996749 5.4062562 ]\n",
      " [0.         1.78432453 1.10743988 ... 5.66446877 0.06041242 5.04420853]]\n",
      "Results for model with 500 features:\n",
      "[[0.00000000e+00 5.26379585e-01 0.00000000e+00 ... 4.04208422e+00\n",
      "  0.00000000e+00 3.28936028e+00]\n",
      " [0.00000000e+00 3.58541489e-01 0.00000000e+00 ... 3.68013716e+00\n",
      "  0.00000000e+00 2.86785245e+00]\n",
      " [0.00000000e+00 4.71834689e-01 0.00000000e+00 ... 3.75646687e+00\n",
      "  0.00000000e+00 3.08093429e+00]\n",
      " ...\n",
      " [0.00000000e+00 4.08848017e-01 1.90867300e-04 ... 3.72580743e+00\n",
      "  0.00000000e+00 2.85540438e+00]\n",
      " [5.25199808e-04 6.50321662e-01 2.53399718e-04 ... 4.29840183e+00\n",
      "  0.00000000e+00 3.25054860e+00]\n",
      " [6.31932984e-04 5.59535205e-01 7.12346984e-04 ... 3.94112468e+00\n",
      "  6.49075591e-05 3.03620815e+00]]\n",
      "Results for model with 1000 features:\n",
      "[[0.00000000e+00 0.00000000e+00 1.08937407e-03 ... 1.19390227e-01\n",
      "  0.00000000e+00 3.84730995e-01]\n",
      " [0.00000000e+00 0.00000000e+00 1.47032901e-03 ... 2.51595944e-01\n",
      "  0.00000000e+00 7.49910653e-01]\n",
      " [0.00000000e+00 0.00000000e+00 9.00225621e-03 ... 2.71604508e-01\n",
      "  0.00000000e+00 5.51597178e-01]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 1.22486064e-02 ... 2.94329792e-01\n",
      "  0.00000000e+00 8.06505620e-01]\n",
      " [0.00000000e+00 0.00000000e+00 2.29550432e-02 ... 2.30753690e-01\n",
      "  0.00000000e+00 7.29299486e-01]\n",
      " [0.00000000e+00 0.00000000e+00 1.35309855e-02 ... 2.35693783e-01\n",
      "  3.88010347e-04 7.32983232e-01]]\n",
      "Results for model with 2000 features:\n",
      "[[3.63295414e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 4.06479263e+00]\n",
      " [1.12959389e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 3.21253324e+00]\n",
      " [3.63225043e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  6.46341220e-03 3.27231765e+00]\n",
      " ...\n",
      " [2.67392807e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  1.02805812e-02 3.13683963e+00]\n",
      " [6.70543090e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  2.61496031e-03 3.85508347e+00]\n",
      " [2.53087021e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  6.57966128e-03 3.74342251e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to store results for each model\n",
    "output_dict0 = {}\n",
    "\n",
    "# Loop over each model\n",
    "for model in models:\n",
    "    x_all = np.zeros((processed_grid_list[0].shape[0], model.num_features), dtype=float)\n",
    "\n",
    "    tic = time.time()\n",
    "    i = 0\n",
    "\n",
    "    # Iterate over each image in the dataloader\n",
    "    for images in dataloaders[0]:\n",
    "        for image in images:\n",
    "            if image is not None and image.shape[0] >= 0 and image.shape[2] >= 0:\n",
    "                image = image.to()\n",
    "                with torch.no_grad():\n",
    "                    feats = model(image.unsqueeze(0)).cpu().numpy()\n",
    "\n",
    "                x_all[i] = feats\n",
    "\n",
    "                if i % 1000 == 0:\n",
    "                    print(\n",
    "                        f\"{i}/{processed_grid_list[0].shape[0]} -- {i / processed_grid_list[0].shape[0] * 100:0.2f}%\"\n",
    "                        + f\" -- {time.time()-tic:0.2f} seconds\"\n",
    "                    )\n",
    "                    tic = time.time()\n",
    "\n",
    "                i += 1\n",
    "\n",
    "                # Check if i exceeds the number of points, break the loop\n",
    "                if i >= processed_grid_list[0].shape[0]:\n",
    "                    break\n",
    "\n",
    "        # Check if i exceeds the number of points, break the loop\n",
    "        if i >= processed_grid_list[0].shape[0]:\n",
    "            break\n",
    "\n",
    "    # Store x_all in the dictionary for the current model\n",
    "    output_dict0[model.num_features] = x_all\n",
    "\n",
    "# Access the results for each model\n",
    "for num_features, x_all in output_dict0.items():\n",
    "    print(f\"Results for model with {num_features} features:\")\n",
    "    print(x_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020aa810-cc7d-40fe-b276-89e803f53175",
   "metadata": {},
   "source": [
    "### Cluster the patches based on features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "57e2020f-d437-4e3a-a6de-df1b8f84ef69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame to store the scores\n",
    "scores_df = pd.DataFrame(columns=[\n",
    "    'sil_score',\n",
    "    'cal_score',\n",
    "    'db_score',\n",
    "    'gap_stat',\n",
    "    'num_feats',\n",
    "    'num_clus',\n",
    "    'scale'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ac6a75c8-0850-4e20-910e-ecc37f4e93ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the fixed number of clusters\n",
    "cluster_sizes = [3, 10, 18, 25]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7d9c087e-968b-4498-b77a-7995d59ba0b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_dict9 = {}\n",
    "\n",
    "# Iterate over cluster sizes\n",
    "for k in cluster_sizes:\n",
    "    # Iterate over different num_features values (assuming they are keys in output_dict8)\n",
    "    for num_features, data_scaled in output_dict9.items():\n",
    "        data_scaled = StandardScaler().fit_transform(data_scaled)\n",
    "\n",
    "        # Fit KMeans model for the original data\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        labels = kmeans.fit_predict(data_scaled)\n",
    "\n",
    "        # Calculate scores for the original data\n",
    "        silhouette = silhouette_score(data_scaled, labels)\n",
    "        calinski_harabasz = calinski_harabasz_score(data_scaled, labels)\n",
    "        davies_bouldin = davies_bouldin_score(data_scaled, labels)\n",
    "        # Convert the dictionary to a DataFrame\n",
    "                # Store labels in the dictionary\n",
    "        labels_dict9[(num_features, k)] = labels\n",
    "        labels_df9 = pd.DataFrame(labels_dict9)\n",
    "        \n",
    "        # Flatten the multi-level columns into a single level\n",
    "        labels_df9.columns = ['{}_{}'.format(col[0], col[1]) for col in labels_df9.columns]\n",
    "        labels_df9.to_csv('labels_df9.csv')\n",
    "        \n",
    "        # Append scores to the DataFrame\n",
    "        scores_df = pd.concat([scores_df, pd.DataFrame({\n",
    "            'sil_score': silhouette,\n",
    "            'cal_score': calinski_harabasz,\n",
    "            'db_score': davies_bouldin,\n",
    "            'gap_stat': gap_clusters,\n",
    "            'num_feats': num_features,\n",
    "            'num_clus': k,\n",
    "            'scale': '370',  # You can adjust this based on your scaling method\n",
    "#            'gap_stat': 'gap_statistic',\n",
    "        }, index=[0])], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "866c951a-c679-477d-90ec-0455855716e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of labels is 1. Valid values are 2 to n_samples - 1 (inclusive)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m labels \u001b[38;5;241m=\u001b[39m kmeans\u001b[38;5;241m.\u001b[39mfit_predict(data_scaled)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Calculate scores for the original data\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m silhouette \u001b[38;5;241m=\u001b[39m \u001b[43msilhouette_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m calinski_harabasz \u001b[38;5;241m=\u001b[39m calinski_harabasz_score(data_scaled, labels)\n\u001b[1;32m     16\u001b[0m davies_bouldin \u001b[38;5;241m=\u001b[39m davies_bouldin_score(data_scaled, labels)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/metrics/cluster/_unsupervised.py:117\u001b[0m, in \u001b[0;36msilhouette_score\u001b[0;34m(X, labels, metric, sample_size, random_state, **kwds)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         X, labels \u001b[38;5;241m=\u001b[39m X[indices], labels[indices]\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(\u001b[43msilhouette_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/metrics/cluster/_unsupervised.py:231\u001b[0m, in \u001b[0;36msilhouette_samples\u001b[0;34m(X, labels, metric, **kwds)\u001b[0m\n\u001b[1;32m    229\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(labels)\n\u001b[1;32m    230\u001b[0m label_freqs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbincount(labels)\n\u001b[0;32m--> 231\u001b[0m \u001b[43mcheck_number_of_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m metric\n\u001b[1;32m    234\u001b[0m reduce_func \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[1;32m    235\u001b[0m     _silhouette_reduce, labels\u001b[38;5;241m=\u001b[39mlabels, label_freqs\u001b[38;5;241m=\u001b[39mlabel_freqs\n\u001b[1;32m    236\u001b[0m )\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/metrics/cluster/_unsupervised.py:33\u001b[0m, in \u001b[0;36mcheck_number_of_labels\u001b[0;34m(n_labels, n_samples)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that number of labels are valid.\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    Number of samples.\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m n_labels \u001b[38;5;241m<\u001b[39m n_samples:\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of labels is \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. Valid values are 2 to n_samples - 1 (inclusive)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;241m%\u001b[39m n_labels\n\u001b[1;32m     36\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Number of labels is 1. Valid values are 2 to n_samples - 1 (inclusive)"
     ]
    }
   ],
   "source": [
    "labels_dict8 = {}\n",
    "\n",
    "# Iterate over cluster sizes\n",
    "for k in cluster_sizes:\n",
    "    # Iterate over different num_features values (assuming they are keys in output_dict8)\n",
    "    for num_features, data_scaled in output_dict8.items():\n",
    "        data_scaled = StandardScaler().fit_transform(data_scaled)\n",
    "\n",
    "        # Fit KMeans model for the original data\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        labels = kmeans.fit_predict(data_scaled)\n",
    "\n",
    "        # Calculate scores for the original data\n",
    "        silhouette = silhouette_score(data_scaled, labels)\n",
    "        calinski_harabasz = calinski_harabasz_score(data_scaled, labels)\n",
    "        davies_bouldin = davies_bouldin_score(data_scaled, labels)\n",
    "        \n",
    "         # Convert the dictionary to a DataFrame\n",
    "        labels_dict8[(num_features, k)] = labels\n",
    "        labels_df8 = pd.DataFrame(labels_dict8)\n",
    "        labels_df8.columns = ['{}_{}'.format(col[0], col[1]) for col in labels_df8.columns]\n",
    "        labels_df8.to_csv('labels_df8.csv')\n",
    "        \n",
    "        # Append scores to the DataFrame\n",
    "        scores_df = pd.concat([scores_df, pd.DataFrame({\n",
    "            'sil_score': silhouette,\n",
    "            'cal_score': calinski_harabasz,\n",
    "            'db_score': davies_bouldin,\n",
    "            'num_feats': num_features,\n",
    "            'num_clus': k,\n",
    "            'scale': '330',  # You can adjust this based on your scaling method\n",
    "        }, index=[0])], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552cddf4-b8b3-4a40-801e-12d612ff1bbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_dict7 = {}\n",
    "\n",
    "# Iterate over cluster sizes\n",
    "for k in cluster_sizes:\n",
    "    # Iterate over different num_features values (assuming they are keys in output_dict8)\n",
    "    for num_features, data_scaled in output_dict7.items():\n",
    "        data_scaled = StandardScaler().fit_transform(data_scaled)\n",
    "\n",
    "        # Fit KMeans model for the original data\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        labels = kmeans.fit_predict(data_scaled)\n",
    "\n",
    "        # Calculate scores for the original data\n",
    "        silhouette = silhouette_score(data_scaled, labels)\n",
    "        calinski_harabasz = calinski_harabasz_score(data_scaled, labels)\n",
    "        davies_bouldin = davies_bouldin_score(data_scaled, labels)\n",
    "        \n",
    "        # Convert the dictionary to a DataFrame\n",
    "        # Convert the dictionary to a DataFrame\n",
    "        labels_dict7[(num_features, k)] = labels\n",
    "        labels_df7 = pd.DataFrame(labels_dict7)\n",
    "        labels_df7.columns = ['{}_{}'.format(col[0], col[1]) for col in labels_df7.columns]\n",
    "        labels_df7.to_csv('labels_df7.csv')\n",
    "        \n",
    "        # Append scores to the DataFrame\n",
    "        scores_df = pd.concat([scores_df, pd.DataFrame({\n",
    "            'sil_score': silhouette,\n",
    "            'cal_score': calinski_harabasz,\n",
    "            'db_score': davies_bouldin,\n",
    "            'gap_stat': gap_clusters,\n",
    "            'num_feats': num_features,\n",
    "            'num_clus': k,\n",
    "            'scale': '290',  # You can adjust this based on your scaling method\n",
    "        }, index=[0])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5a1b1bf3-1d20-4a5d-938e-1c28022b8bd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/scipy/cluster/vq.py:602: UserWarning: One of the clusters is empty. Re-run kmeans with a different initialization.\n",
      "  warnings.warn(\"One of the clusters is empty. \"\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/scipy/cluster/vq.py:602: UserWarning: One of the clusters is empty. Re-run kmeans with a different initialization.\n",
      "  warnings.warn(\"One of the clusters is empty. \"\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/scipy/cluster/vq.py:602: UserWarning: One of the clusters is empty. Re-run kmeans with a different initialization.\n",
      "  warnings.warn(\"One of the clusters is empty. \"\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/scipy/cluster/vq.py:602: UserWarning: One of the clusters is empty. Re-run kmeans with a different initialization.\n",
      "  warnings.warn(\"One of the clusters is empty. \"\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/scipy/cluster/vq.py:602: UserWarning: One of the clusters is empty. Re-run kmeans with a different initialization.\n",
      "  warnings.warn(\"One of the clusters is empty. \"\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/scipy/cluster/vq.py:602: UserWarning: One of the clusters is empty. Re-run kmeans with a different initialization.\n",
      "  warnings.warn(\"One of the clusters is empty. \"\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/scipy/cluster/vq.py:602: UserWarning: One of the clusters is empty. Re-run kmeans with a different initialization.\n",
      "  warnings.warn(\"One of the clusters is empty. \"\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/scipy/cluster/vq.py:602: UserWarning: One of the clusters is empty. Re-run kmeans with a different initialization.\n",
      "  warnings.warn(\"One of the clusters is empty. \"\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/scipy/cluster/vq.py:602: UserWarning: One of the clusters is empty. Re-run kmeans with a different initialization.\n",
      "  warnings.warn(\"One of the clusters is empty. \"\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "labels_dict6 = {}            \n",
    "\n",
    "# Iterate over cluster sizes\n",
    "for k in cluster_sizes:\n",
    "    # Iterate over different num_features values (assuming they are keys in output_dict8)\n",
    "    for num_features, data_scaled in output_dict6.items():\n",
    "        data_scaled = StandardScaler().fit_transform(data_scaled)\n",
    "\n",
    "        # Fit KMeans model for the original data\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        labels = kmeans.fit_predict(data_scaled)\n",
    "\n",
    "        # Calculate scores for the original data\n",
    "        silhouette = silhouette_score(data_scaled, labels)\n",
    "        calinski_harabasz = calinski_harabasz_score(data_scaled, labels)\n",
    "        davies_bouldin = davies_bouldin_score(data_scaled, labels)\n",
    "        \n",
    "        # Convert the dictionary to a DataFrame\n",
    "        # Convert the dictionary to a DataFrame\n",
    "        labels_dict6[(num_features, k)] = labels\n",
    "        labels_df6 = pd.DataFrame(labels_dict6)\n",
    "        labels_df6.columns = ['{}_{}'.format(col[0], col[1]) for col in labels_df6.columns]\n",
    "        labels_df6.to_csv('labels_df6.csv')\n",
    "             \n",
    "        \n",
    "        # Append scores to the DataFrame\n",
    "        scores_df = pd.concat([scores_df, pd.DataFrame({\n",
    "            'sil_score': silhouette,\n",
    "            'cal_score': calinski_harabasz,\n",
    "            'db_score': davies_bouldin,\n",
    "            'gap_stat': gap_clusters,\n",
    "            'num_feats': num_features,\n",
    "            'num_clus': k,\n",
    "            'scale': '250',  # You can adjust this based on your scaling method\n",
    "        }, index=[0])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1e71c56e-c543-444f-be62-e1112df74d6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "labels_dict5 = {}  \n",
    "\n",
    "# Iterate over cluster sizes\n",
    "for k in cluster_sizes:\n",
    "    # Iterate over different num_features values (assuming they are keys in output_dict8)\n",
    "    for num_features, data_scaled in output_dict5.items():\n",
    "        data_scaled = StandardScaler().fit_transform(data_scaled)\n",
    "\n",
    "        # Fit KMeans model for the original data\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        labels = kmeans.fit_predict(data_scaled)\n",
    "\n",
    "        # Calculate scores for the original data\n",
    "        silhouette = silhouette_score(data_scaled, labels)\n",
    "        calinski_harabasz = calinski_harabasz_score(data_scaled, labels)\n",
    "        davies_bouldin = davies_bouldin_score(data_scaled, labels)\n",
    "        \n",
    "        # Convert the dictionary to a DataFrame\n",
    "        # Convert the dictionary to a DataFrame\n",
    "        labels_dict5[(num_features, k)] = labels\n",
    "        labels_df5 = pd.DataFrame(labels_dict5)\n",
    "        labels_df5.columns = ['{}_{}'.format(col[0], col[1]) for col in labels_df5.columns]\n",
    "        labels_df5.to_csv('labels_df5.csv')\n",
    "             \n",
    "\n",
    "        \n",
    "        # Append scores to the DataFrame\n",
    "        scores_df = pd.concat([scores_df, pd.DataFrame({\n",
    "            'sil_score': silhouette,\n",
    "            'cal_score': calinski_harabasz,\n",
    "            'db_score': davies_bouldin,\n",
    "            'gap_stat': gap_clusters,\n",
    "            'num_feats': num_features,\n",
    "            'num_clus': k,\n",
    "            'scale': '210',  # You can adjust this based on your scaling method\n",
    "        }, index=[0])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7398beb-ef32-4726-9ebe-46f111158d2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "labels_dict4 = {}  \n",
    "\n",
    "# Iterate over cluster sizes\n",
    "for k in cluster_sizes:\n",
    "    # Iterate over different num_features values (assuming they are keys in output_dict8)\n",
    "    for num_features, data_scaled in output_dict4.items():\n",
    "        data_scaled = StandardScaler().fit_transform(data_scaled)\n",
    "\n",
    "        # Fit KMeans model for the original data\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        labels = kmeans.fit_predict(data_scaled)\n",
    "\n",
    "        # Calculate scores for the original data\n",
    "        silhouette = silhouette_score(data_scaled, labels)\n",
    "        calinski_harabasz = calinski_harabasz_score(data_scaled, labels)\n",
    "        davies_bouldin = davies_bouldin_score(data_scaled, labels)\n",
    "        \n",
    "        # Convert the dictionary to a DataFrame\n",
    "        # Convert the dictionary to a DataFrame\n",
    "        labels_dict4[(num_features, k)] = labels\n",
    "        labels_df4 = pd.DataFrame(labels_dict4)\n",
    "        labels_df4.columns = ['{}_{}'.format(col[0], col[1]) for col in labels_df4.columns]\n",
    "        labels_df4.to_csv('labels_df4.csv')\n",
    "             \n",
    "\n",
    "        # Append scores to the DataFrame\n",
    "        scores_df = pd.concat([scores_df, pd.DataFrame({\n",
    "            'sil_score': silhouette,\n",
    "            'cal_score': calinski_harabasz,\n",
    "            'db_score': davies_bouldin,\n",
    "            'gap_stat': gap_clusters,\n",
    "            'num_feats': num_features,\n",
    "            'num_clus': k,\n",
    "            'scale': '170',  # You can adjust this based on your scaling method\n",
    "        }, index=[0])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "086764f7-42b2-4096-9864-6465762a563d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/scipy/cluster/vq.py:602: UserWarning: One of the clusters is empty. Re-run kmeans with a different initialization.\n",
      "  warnings.warn(\"One of the clusters is empty. \"\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/scipy/cluster/vq.py:602: UserWarning: One of the clusters is empty. Re-run kmeans with a different initialization.\n",
      "  warnings.warn(\"One of the clusters is empty. \"\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/scipy/cluster/vq.py:602: UserWarning: One of the clusters is empty. Re-run kmeans with a different initialization.\n",
      "  warnings.warn(\"One of the clusters is empty. \"\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/scipy/cluster/vq.py:602: UserWarning: One of the clusters is empty. Re-run kmeans with a different initialization.\n",
      "  warnings.warn(\"One of the clusters is empty. \"\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/scipy/cluster/vq.py:602: UserWarning: One of the clusters is empty. Re-run kmeans with a different initialization.\n",
      "  warnings.warn(\"One of the clusters is empty. \"\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/scipy/cluster/vq.py:602: UserWarning: One of the clusters is empty. Re-run kmeans with a different initialization.\n",
      "  warnings.warn(\"One of the clusters is empty. \"\n"
     ]
    }
   ],
   "source": [
    "labels_dict3 = {}  \n",
    "# Iterate over cluster sizes\n",
    "for k in cluster_sizes:\n",
    "    # Iterate over different num_features values (assuming they are keys in output_dict8)\n",
    "    for num_features, data_scaled in output_dict3.items():\n",
    "        data_scaled = StandardScaler().fit_transform(data_scaled)\n",
    "\n",
    "        # Fit KMeans model for the original data\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        labels = kmeans.fit_predict(data_scaled)\n",
    "\n",
    "        # Calculate scores for the original data\n",
    "        silhouette = silhouette_score(data_scaled, labels)\n",
    "        calinski_harabasz = calinski_harabasz_score(data_scaled, labels)\n",
    "        davies_bouldin = davies_bouldin_score(data_scaled, labels)\n",
    "        \n",
    "        \n",
    "        # Convert the dictionary to a DataFrame\n",
    "        # Convert the dictionary to a DataFrame\n",
    "        labels_dict3[(num_features, k)] = labels\n",
    "        labels_df3 = pd.DataFrame(labels_dict3)\n",
    "        labels_df3.columns = ['{}_{}'.format(col[0], col[1]) for col in labels_df3.columns]\n",
    "        labels_df3.to_csv('labels_df3.csv')\n",
    "             \n",
    "        # Append scores to the DataFrame\n",
    "        scores_df = pd.concat([scores_df, pd.DataFrame({\n",
    "            'sil_score': silhouette,\n",
    "            'cal_score': calinski_harabasz,\n",
    "            'db_score': davies_bouldin,\n",
    "            'gap_stat': gap_clusters,\n",
    "            'num_feats': num_features,\n",
    "            'num_clus': k,\n",
    "            'scale': '130',  # You can adjust this based on your scaling method\n",
    "        }, index=[0])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "87d5c283-7a4d-4e7f-af47-23ba7fcb27be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/utils/extmath.py:189: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/utils/extmath.py:189: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/utils/extmath.py:189: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/utils/extmath.py:189: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    }
   ],
   "source": [
    "labels_dict2 = {}  \n",
    "# Iterate over cluster sizes\n",
    "for k in cluster_sizes:\n",
    "    # Iterate over different num_features values (assuming they are keys in output_dict8)\n",
    "    for num_features, data_scaled in output_dict2.items():\n",
    "        data_scaled = StandardScaler().fit_transform(data_scaled)\n",
    "\n",
    "        # Fit KMeans model for the original data\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        labels = kmeans.fit_predict(data_scaled)\n",
    "\n",
    "        # Calculate scores for the original data\n",
    "        silhouette = silhouette_score(data_scaled, labels)\n",
    "        calinski_harabasz = calinski_harabasz_score(data_scaled, labels)\n",
    "        davies_bouldin = davies_bouldin_score(data_scaled, labels)\n",
    "        \n",
    "        # Convert the dictionary to a DataFrame\n",
    "        # Convert the dictionary to a DataFrame\n",
    "        labels_dict2[(num_features, k)] = labels\n",
    "        labels_df2 = pd.DataFrame(labels_dict2)\n",
    "        labels_df2.columns = ['{}_{}'.format(col[0], col[1]) for col in labels_df2.columns]\n",
    "        labels_df2.to_csv('labels_df2.csv')\n",
    "        \n",
    "\n",
    "        # Append scores to the DataFrame\n",
    "        scores_df = pd.concat([scores_df, pd.DataFrame({\n",
    "            'sil_score': silhouette,\n",
    "            'cal_score': calinski_harabasz,\n",
    "            'db_score': davies_bouldin,\n",
    "            'gap_stat': gap_clusters,\n",
    "            'num_feats': num_features,\n",
    "            'num_clus': k,\n",
    "            'scale': '90',  # You can adjust this based on your scaling method\n",
    "        }, index=[0])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5402b6dd-9112-46a6-9612-e4f085da6c47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/utils/extmath.py:189: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/utils/extmath.py:189: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/utils/extmath.py:189: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/utils/extmath.py:189: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/utils/extmath.py:189: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/utils/extmath.py:189: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/utils/extmath.py:189: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/utils/extmath.py:189: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/utils/extmath.py:189: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/utils/extmath.py:189: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/utils/extmath.py:189: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/utils/extmath.py:189: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    }
   ],
   "source": [
    "labels_dict1 = {}  \n",
    "# Iterate over cluster sizes\n",
    "for k in cluster_sizes:\n",
    "    # Iterate over different num_features values (assuming they are keys in output_dict8)\n",
    "    for num_features, data_scaled in output_dict1.items():\n",
    "        data_scaled = StandardScaler().fit_transform(data_scaled)\n",
    "\n",
    "        # Fit KMeans model for the original data\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        labels = kmeans.fit_predict(data_scaled)\n",
    "\n",
    "        # Calculate scores for the original data\n",
    "        silhouette = silhouette_score(data_scaled, labels)\n",
    "        calinski_harabasz = calinski_harabasz_score(data_scaled, labels)\n",
    "        davies_bouldin = davies_bouldin_score(data_scaled, labels)\n",
    "        \n",
    "        # Convert the dictionary to a DataFrame\n",
    "        # Convert the dictionary to a DataFrame\n",
    "        labels_dict1[(num_features, k)] = labels\n",
    "        labels_df1 = pd.DataFrame(labels_dict1)\n",
    "        labels_df1.columns = ['{}_{}'.format(col[0], col[1]) for col in labels_df1.columns]\n",
    "        labels_df1.to_csv('labels_df1.csv')\n",
    "\n",
    "        \n",
    "        # Append scores to the DataFrame\n",
    "        scores_df = pd.concat([scores_df, pd.DataFrame({\n",
    "            'sil_score': silhouette,\n",
    "            'cal_score': calinski_harabasz,\n",
    "            'db_score': davies_bouldin,\n",
    "            'gap_stat': gap_clusters,\n",
    "            'num_feats': num_features,     \n",
    "            'num_clus': k,\n",
    "            'scale': '50',  # You can adjust this based on your scaling method\n",
    "        }, index=[0])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8739ae-1755-40bf-95a5-63775c005137",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "labels_dict0 = {}  \n",
    "# Iterate over cluster sizes\n",
    "for k in cluster_sizes:\n",
    "    # Iterate over different num_features values (assuming they are keys in output_dict8)\n",
    "    for num_features, data_scaled in output_dict0.items():\n",
    "        data_scaled = StandardScaler().fit_transform(data_scaled)\n",
    "\n",
    "        # Fit KMeans model for the original data\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        labels = kmeans.fit_predict(data_scaled)\n",
    "\n",
    "        # Calculate scores for the original data\n",
    "        silhouette = silhouette_score(data_scaled, labels)\n",
    "        calinski_harabasz = calinski_harabasz_score(data_scaled, labels)\n",
    "        davies_bouldin = davies_bouldin_score(data_scaled, labels)\n",
    "        \n",
    "        # Convert the dictionary to a DataFrame\n",
    "        # Convert the dictionary to a DataFrame\n",
    "        labels_dict0[(num_features, k)] = labels\n",
    "        labels_df0 = pd.DataFrame(labels_dict0)\n",
    "        labels_df0.columns = ['{}_{}'.format(col[0], col[1]) for col in labels_df0.columns]\n",
    "        labels_df0.to_csv('labels_df0.csv')\n",
    "        \n",
    "        # Append scores to the DataFrame\n",
    "        scores_df = pd.concat([scores_df, pd.DataFrame({\n",
    "            'sil_score': silhouette,\n",
    "            'cal_score': calinski_harabasz,\n",
    "            'db_score': davies_bouldin,\n",
    "            'gap_stat': gap_clusters,\n",
    "            'num_feats': num_features,\n",
    "            'num_clus': k,\n",
    "            'scale': '30'  # You can adjust this based on your scaling method\n",
    "            }, index=[0])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5d68e0-e4c5-488d-b784-3bb3541f1a3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the scores to a csv for further analysis\n",
    "scores_df.to_csv('scores_cluster2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
